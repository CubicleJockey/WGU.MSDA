{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# D209 Data Mining I Performance Assessment - Task 2\n",
    "### NVM2 — NVM2 Task 2: Predictive Analysis\n",
    "#### Data Mining I — D209\n",
    "#### PRFA — NVM2\n",
    "> André Davis\n",
    "> StudentID: 010630641\n",
    "> MSDA\n",
    ">\n",
    "> Competencies\n",
    "> 4030.06.1 : Classification Data Mining Models\n",
    ">   The graduate applies observations to appropriate classes and categories using classification models.\n",
    ">\n",
    "> 4030.06.3 : Data Mining Model Performance\n",
    ">   The graduate evaluates data mining model performance for precision, accuracy, and model comparison.\n",
    "\n",
    "#### Table of Contents\n",
    "<ul>\n",
    "    <li><a href=\"#research-question\">A1: Research Question</li>\n",
    "    <li><a href=\"#goal-of-analysis\">A2: Objectives and Goals of Analysis</a></li>\n",
    "    <li><a href=\"#justification\">B1: Justification of Classification Method</a></li>\n",
    "    <li><a href=\"#assumption-of-classification\">B2: Assumptions of a Classification Model</a></li>\n",
    "    <li><a href=\"#packages-and-analysis-support\">B3: Benefits of Chosen Tools</a></li>\n",
    "    <li><a href=\"#data-preparation-goals\">C1: Data Preparation Goals and Necessary Manipulation</a></li>\n",
    "    <li><a href=\"#variable-selection-and-identification\">C2: Variable Selection \\& Identification</a></li>\n",
    "    <li><a href=\"#data-preparation\">C3: Preparation of Data</a></li>\n",
    "    <li><a href=\"#copy-of-prepared-data\">C4: Copy of Prepared Data Set</a></li>\n",
    "    <li><a href=\"#data-splitting-and-copying\">D1: Data Splitting, Copy of Split Data</a></li>\n",
    "    <li><a href=\"#analysis-description\">D2: Analysis Description</a></li>\n",
    "    <li><a href=\"#classification-analysis-code\">D3: Classification Analysis Code</a></li>\n",
    "    <li><a href=\"#accuracy-of-classification-model\">E1: Accuracy of Classification Model</a></li>\n",
    "    <li><a href=\"#model-results\">E2: Model Results</a></li>\n",
    "    <li><a href=\"#classification-limitation\">E3: Classification Limitations</a></li>\n",
    "    <li><a href=\"#recommended-action\">E4: Recommended Action</a></li>\n",
    "    <li><a href=\"#panopto-recording\">F: Panopto Recording</a></li>\n",
    "    <li><a href=\"#code-references\">G: Code References</a></li>\n",
    "    <li><a href=\"#source-references\">H: Source References</a></li>\n",
    "</ul>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"research-question\"></a>\n",
    "# A1: Research Question\n",
    "\n",
    "*Answer your question using one of the following methods:* [`Decision Tree`](https://scikit-learn.org/stable/modules/tree.html), [`Random Forest`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), [`Advanced Refression - Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html), or [`Advanced Regression - Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "In D208 Task 2 (Logistical Regression) and D209 Task 1 (Classification Analysis - k-nearest neighbor (KNN) I've been attempting to get the best model for answering `\"Which factors have a significant effect on readmission?\"` So far I've approached this question 2 different ways and have come up with pretty reasonable models with high accuracy and lost MSE *(Means Squared Error)*.\n",
    "\n",
    "I am going to attempt to generate a better model for predicting readmission using the `Decision Tree` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"objectives-and-goals\"></a>\n",
    "# A2: Objective and Goals of Analysis\n",
    "\n",
    "Because *D208 (Logical Regression)* and *D209 Task 1 - (Classification: k-nearest neighbor)* both had accuracies in the neighborhood of *0.97 (97%)* and *0.98 (8%)*. The objective is to answer A1: Question of `\"Which factors have a significant effect on readmission?\"` while the goal of this method of `Decision Tree` is to meet the same level of accuracy but bring easier interpretation with a method that can handle categorical and numerical data with complex relationships."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"justification\"></a>\n",
    "# B1: Justification of Classification Method\n",
    "\n",
    "Because the [Logistics Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and [k-nearest Neighbor (KNN)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) both had high accuracy and low MSE values, I wanted a model that could increase understandability. A decision tree out of the choices listed for A1 met these criteria.\n",
    "\n",
    "A `Decision Tree` is similar to a flowchart for making choices. A decision tree is a graphical representation of a decision-making process that helps in identifying the possible outcomes given a series of related choices. Visually, when given a data point, it starts at a root node and branches out into various possible outcomes or paths based on the decisions made at each node. Each decision is represented by a branch, and each outcome is represented by a leaf node.\n",
    "\n",
    "Another way to say this is that \"A tree model is a set of \"if-then-else\" rules that are easy to understand and to implement.\" (Bruce, P., Bruce, A., & Gedeck, P.  2019 p.250)\n",
    "\n",
    "Because of its flowchart appearance this makes `Decision Tree` easy to understand and interpret. Because of this easy visualization, it makes communicating a complex decision-making process to everyone in a team accessible.\n",
    "<br/>\n",
    "##### Expected Outcome (Revision - Attempt 2):\n",
    "\n",
    "Because the D208 Task 2 Logistical Regression and D209 Task 1 both had a high accuracy in the 97% - 98% range, it would be reasonable to expect that a Decision Tree Model which is visually easier to explain to a client would fall within the range of 97% - 99% as well. The explanatory variables choice to answer the question in A1 seems to be holding true per course and data analytics methodology. In the end, we are expecting the decision tree to maintain a high accuracy with a low MSE meaning that its representation to the question of A1 is trustworthy.\n",
    "\n",
    "The second expectation is that even though the Decision Tree accuracy is not going to increase or decrease the previous models significantly that adding ADA Boost to the decision tree would turn out the same. The accuracy would stay within the 97% - 99% the previous models have."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"classification-model\"></a>\n",
    "# B2: Assumptions of a Classification Model\n",
    "\n",
    "Assumptions:\n",
    "\n",
    " * Features are independent of each other.\n",
    " * Classes used are balanced\n",
    " * Non-linear relationships between input and output variables.\n",
    " * \"Discretion of continuous variables is required.\" (MyGreatLearning, n.d.)\n",
    " * \"The data taken for training should be wholly considered as root\" (MyGreatLearning, n.d.)\n",
    " * \"Distribution of records is done in a recursive manner on the basis of attribute values.\" (MyGreatLearning, n.d.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"packages-and-analysis-support\"></a>\n",
    "# B3: List Packages & Support of Analysis\n",
    "\n",
    "#### Analytic package for Python:\n",
    " * **Data manipulation:**\n",
    "    * [Pandas](https://pandas.pydata.org/docs/)\n",
    "      - Pandas library is used for data manipulation, analysis, and cleaning. Pandas' main data structures are the Series (1-dimensional) and DataFrame (2-dimensional).\n",
    "          - [Version 2](https://towardsdatascience.com/whats-new-in-pandas-2-0-5df366eb0197) is coming soon and will replace NumPy with Apache Arrows.\n",
    "    * [NumPy](https://numpy.org/doc/)\n",
    "         - Library used for numerical computing. It provides support for multidimensional arrays, matrices, and high-level mathematical functions to perform complex computations quickly and efficiently.\n",
    " * **Displaying Data:**\n",
    "    * [MatPlotLib](https://matplotlib.org/)\n",
    "        * This is a data visualization library.\n",
    " * **Analysis:**\n",
    "    * SkLearn (Scikit-learn - Machine Learning):\n",
    "        * [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "        * [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "        * [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "        * [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "        * [GradientBoostingRegressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.GradientBoostingRegressor.html)\n",
    "        * [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "        * [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "        * [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "        * [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
    "        * [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "        * [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "        * [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import textwrap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier, GradientBoostingRegressor\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, accuracy_score, mean_squared_error as MSE\n",
    "\n",
    "SEED = 42\n",
    "\n",
    "#load the data ignoring the first column as it's simply an index\n",
    "medical_data = pd.read_csv('./Data/Medical/medical_clean.csv', index_col=0)\n",
    "medical_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T23:12:30.356838Z",
     "end_time": "2023-04-30T23:12:32.822041Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-preparation-goals\"></a>\n",
    "# C1: Data Preparation Goals and Necessary Manipulation\n",
    "\n",
    " * D209 - *Data Mining I* is continuation of datasets from *D206 - Data Cleaning* and is given to us pre-cleaned to a point. Listed below are items pre-completed (NOTE: If data was completely raw [Imputer](https://scikit-learn.org/0.16/modules/generated/sklearn.preprocessing.Imputer.html) and [Pipeline](https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html) would be really helpful compared to the actions of D206):\n",
    "     * Detecting Duplicates\n",
    "     * Dealing with missing values\n",
    "     * Detecting Outliers\n",
    " * Hot Encoding (*Dummy Variables* or *Indicator Variables*)\n",
    "     * \"Is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\" (Vasudev, 2017).\n",
    "     * \"Binary 0-1 variables derived by recoding factor data for use in regression and other models\" (Bruce, P., Bruce, A., & Gedeck, P.  2019 p.163)\n",
    "     * If you have a Series that has 3 categorical levels, you can split your series into two variables to represent the three states. If you have blue, yellow, and black and convert them to 1/0's, then you only need two columns for the 3 series. For example, if you have yellow = 0, and black = 0, then that means your value is blue without having that datapoint. We can apply this to the `Complication Risk` series in the dataset. It includes Low, Medium, and High. If we use the High (Series) and the Low (Series) it can be assumed if High and Low are both 0 values, then the value represented is Medium.\n",
    "     * Pandas function for Hot-Encoding is `pd.get_dummies(data)` documentation is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"variable-selection-and-identification\"></a>\n",
    "# C2: Variable Selection & Identification\n",
    "\n",
    "I am continuing on with the question from D208, so my variables are going to be reused to see if we can get better results with the *k-nearest neighbor (KNN)* model. Below are the variables that were used during logistic regression. Like before survey and census data it was not relevant when looking for explanatory variables that were significant to readmission's (`ReAdmin`) to the hospital.\n",
    "\n",
    "| Data Type    | Variable                              |\n",
    "|--------------|---------------------------------------|\n",
    "| Continuous   | \tNumber of Children                   |\n",
    "| Continuous   | \tVitamin D levels                     |\n",
    "| Continuous   | \tNumber of Dr Visits                  |\n",
    "| Continuous   | \tNumber of Vitamin D supplements      |\n",
    "| Continuous   | \tFull meals                           |\n",
    "| Categorical  | Area (Rural, Suburban, Urban)         |\n",
    "| Categorical  | Gender (Male, Female, Nonbinary)      |\n",
    "| Categorical  | Readmission                           |\n",
    "| Categorical  | Soft Drink Consumption                |\n",
    "| Categorical  | Initial Admission Reason              |\n",
    "| Categorical  | High Blood Pressure                   |\n",
    "| Categorical  | Stroke                                |\n",
    "| Categorical  | Complication Risk (Low, Medium, High) |\n",
    "| Categorical  | Overweight                            |\n",
    "| Categorical  | Arthritis                             |\n",
    "| Categorical  | \tDiabetes                             |\n",
    "| Categorical  | \tHyperlipidemia                       |\n",
    "| Categorical  | \tAnxiety                              |\n",
    "| Categorical  | \tAllergic Rhinitis                    |\n",
    "| Categorical\t | Asthma                                |\n",
    "| Categorical\t | Days hospitalized                     |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-preparation\"></a>\n",
    "# C3: Preparation of Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "original_medical = medical_data #storing backup of original data incase it's needed\n",
    "#del medical_clean_data[medical_clean_data.columns[0]]\n",
    "\n",
    "any_missing_values = medical_data.isna().values.any()\n",
    "if not any_missing_values:\n",
    "    print('Medical data does NOT contain any missing values\\n')\n",
    "else:\n",
    "    print('Medical data CONTAINS missing values.\\n')\n",
    "\n",
    "column_renames = {\n",
    "    'Item1': 'Timely_Admission'\n",
    "    ,'Item2': 'Timely_Treatment'\n",
    "    ,'Item3': 'Timely_Visits'\n",
    "    ,'Item4': 'Reliability'\n",
    "    ,'Item5': 'Options'\n",
    "    ,'Item6': 'Hours_Of_Treatment'\n",
    "    ,'Item7': 'Courteous_Staff'\n",
    "    ,'Item8': 'Listening' #Evidence of active listening from Doctor\n",
    "}\n",
    "medical_data.rename(columns=column_renames, inplace=True)\n",
    "#medical_clean_data\n",
    "\n",
    "removal_attributes = ['Customer_id', 'Interaction', 'UID',\n",
    "                      'Zip', 'Lat', 'Lng', 'City', 'State', 'County',\n",
    "                      'Area', 'Job', 'Marital', 'Population', 'TimeZone']\n",
    "\n",
    "medical_clean_data = medical_data.drop(columns=removal_attributes)\n",
    "\n",
    "category_dtype = 'category'\n",
    "convert_to_category = {\n",
    "    'Gender': category_dtype,\n",
    "    'ReAdmis': category_dtype,\n",
    "    'Soft_drink': category_dtype,\n",
    "    'Initial_admin': category_dtype,\n",
    "    'HighBlood': category_dtype,\n",
    "    'Stroke': category_dtype,\n",
    "    'Complication_risk': category_dtype,\n",
    "    'Overweight': category_dtype,\n",
    "    'Arthritis': category_dtype,\n",
    "    'Diabetes': category_dtype,\n",
    "    'Hyperlipidemia': category_dtype,\n",
    "    'BackPain': category_dtype,\n",
    "    'Anxiety': category_dtype,\n",
    "    'Allergic_rhinitis': category_dtype,\n",
    "    'Reflux_esophagitis': category_dtype,\n",
    "    'Asthma': category_dtype,\n",
    "    'Services': category_dtype,\n",
    "    'Timely_Admission': category_dtype,\n",
    "    'Timely_Treatment': category_dtype,\n",
    "    'Timely_Visits': category_dtype,\n",
    "    'Reliability': category_dtype,\n",
    "    'Options': category_dtype,\n",
    "    'Hours_Of_Treatment': category_dtype,\n",
    "    'Courteous_Staff': category_dtype,\n",
    "    'Listening': category_dtype\n",
    "}\n",
    "\n",
    "medical_clean_data = medical_clean_data.astype(convert_to_category)\n",
    "\n",
    "#Logical categorical variables converted to numerical\n",
    "columns_to_reexpress = ['ReAdmis', 'Soft_drink', 'HighBlood', 'Stroke',\n",
    "                        'Overweight', 'Arthritis', 'Diabetes', 'Hyperlipidemia',\n",
    "                        'BackPain', 'Anxiety', 'Allergic_rhinitis', 'Reflux_esophagitis',\n",
    "                        'Asthma']\n",
    "for column in columns_to_reexpress:\n",
    "    medical_clean_data[column] = medical_clean_data[column].map({'Yes': 1, 'No': 0 }).astype(np.int64)\n",
    "\n",
    "categorical_medical_data = medical_clean_data[convert_to_category.keys()]\n",
    "high_cardinalities = categorical_medical_data.nunique() > 3 #(> 3-5 Levels)\n",
    "high_cardinalities = high_cardinalities[high_cardinalities == True]\n",
    "high_cardinalities = list(high_cardinalities.index.values)\n",
    "print('Categoricals with high cardinality to be removed:')\n",
    "print(high_cardinalities)\n",
    "print('\\n')\n",
    "\n",
    "medical_clean_data = medical_clean_data.drop(columns=high_cardinalities)\n",
    "\n",
    "low_cardinalities = [item for item in list(convert_to_category.keys()) if item not in high_cardinalities]\n",
    "print('Categoricals remaining:')\n",
    "print(low_cardinalities)\n",
    "print('\\n')\n",
    "\n",
    "#Re-level ordinal/nominal categoricals\n",
    "complication_risk_dummies = pd.get_dummies(data=medical_clean_data['Complication_risk'], drop_first=True)\n",
    "\n",
    "medical_clean_data['complication_risk_medium'] = complication_risk_dummies['Medium']\n",
    "medical_clean_data['complication_risk_low'] = complication_risk_dummies['Low']\n",
    "\n",
    "initial_admission_dummies = pd.get_dummies(data=medical_clean_data['Initial_admin'], drop_first=True)\n",
    "\n",
    "medical_clean_data['initial_admission_emergency'] = initial_admission_dummies['Emergency Admission']\n",
    "medical_clean_data['initial_admission_observation'] = initial_admission_dummies['Observation Admission']\n",
    "\n",
    "gender_dummies = pd.get_dummies(data=medical_clean_data['Gender'], drop_first=True)\n",
    "\n",
    "medical_clean_data['gender_male'] = gender_dummies['Male']\n",
    "medical_clean_data['gender_non_binary'] = gender_dummies['Nonbinary']\n",
    "\n",
    "decision_tree_variables = ['Children', 'Age', 'VitD_levels', 'HighBlood', 'Overweight', 'Arthritis', 'Diabetes', 'BackPain', 'Asthma', 'Initial_days', 'ReAdmis', 'complication_risk_medium', 'complication_risk_low', 'initial_admission_emergency', 'initial_admission_observation', 'gender_male','gender_non_binary']\n",
    "\n",
    "prepared_medical_data = medical_clean_data[decision_tree_variables]\n",
    "\n",
    "print('Review Each Data Series\\n')\n",
    "for column in prepared_medical_data.columns:\n",
    "    current = prepared_medical_data[column]\n",
    "    if np.issubdtype(current.dtype, np.number):\n",
    "        print(f'{current.describe()}\\n')\n",
    "    else:\n",
    "        print(f'{current.value_counts()}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T23:12:32.835651Z",
     "end_time": "2023-04-30T23:12:32.925502Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"copy-of-prepared-data\"></a>\n",
    "# C4: Copy of Prepared Data Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "copy_of_prepared_medical_data = prepared_medical_data.copy()\n",
    "copy_of_prepared_medical_data.to_csv('./decision-tree-prepared-data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T23:12:32.925816Z",
     "end_time": "2023-04-30T23:12:32.979879Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-splitting-and-copying\"></a>\n",
    "# D1: Data Splitting, Copy of Split Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Split and store dependent (response/target) and independent (explanatory) variables\n",
    "y_target_variable = prepared_medical_data['ReAdmis'].copy()\n",
    "x_explanatory_variables = prepared_medical_data.drop(columns=['ReAdmis']).copy()\n",
    "\n",
    "#Split our data into training and test datasets. We will use the ration of 80% training and 20% test. Stratify will maintain proportions correctly.\n",
    "x_explanatory_training, x_explanatory_test, y_target_training, y_target_test = train_test_split(x_explanatory_variables, y_target_variable, train_size=.8, test_size=.2, random_state=SEED, stratify=y_target_variable)\n",
    "\n",
    "#Save each file for assessment turn-in\n",
    "x_explanatory_training.to_csv('./x_explanatory-training-dataset-task2.csv')\n",
    "x_explanatory_test.to_csv('./x_explanatory-testing-dataset-task2.csv')\n",
    "\n",
    "y_target_training.to_csv('./y_target-training-dataset-task2.csv')\n",
    "y_target_test.to_csv('./y_target-testing-dataset-task2.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T23:12:32.982182Z",
     "end_time": "2023-04-30T23:12:33.049311Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"analysis-description\"></a>\n",
    "# D2: Analysis Description\n",
    "\n",
    "The analysis technique that is being used in `D209 Task 2` is [`Decision Tree Classifier`](https://en.wikipedia.org/wiki/Decision_tree_learning). This is a technique where a feature is feed to the decision tree classification model, and it is processed against the fitted subsets created based on the training data. As a feature is feed into the model, it follows a flowchart like decent until it settles into a classification (subset) that best matches it. This matching of the feature to a subset is a decision/prediction that should hold true for that particular feature.\n",
    "\n",
    "When developing this model, we have to pick the correct `max_depth` and `min_sample_leaf`. `Max_depth` is a variable (*hyperparamter*) that is used to control the complexity of the model. The bigger the value, the more complex the tree becomes, and if it becomes too big this can lead to an over-fitting of the model. We will run a set of depths to a cross-validation process to come up with the ideal number for `max_depth`. `Min_sample_leaf` which is a parameter that is used to set the minimum number of data points to use when determining to create a leaf in the tree or not.  Let's do cross-validate those variables now:"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Hyper Paramter Tuning for Decision Tree and Estimator\n",
    "dt_parameters = {\n",
    "    'min_samples_leaf': np.arange(.04, .24, .02),\n",
    "    'max_depth': np.arange(1, 21, 1)\n",
    "}\n",
    "#print(f'Parameter Grid: {dt_parameters}')\n",
    "\n",
    "decision_tree_estimator = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "#n_jobs controls the amount of parallel processing that can be done. Setting this to -1 means ALL available CPU cores will be used.\n",
    "cross_validation_dt = GridSearchCV(estimator=decision_tree_estimator,\n",
    "                                   param_grid= dt_parameters,\n",
    "                                   scoring='roc_auc',\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "cross_validation_dt.fit(x_explanatory_training, y_target_training)\n",
    "\n",
    "#Get best estimator\n",
    "best_estimator = cross_validation_dt.best_estimator_\n",
    "\n",
    "#Check Best Estimator Test Accuracy Score\n",
    "best_estimator_test_accuracy = best_estimator.score(x_explanatory_test, y_target_test)\n",
    "print(f'Best Estimator Test Accuracy Score: {best_estimator_test_accuracy}')\n",
    "\n",
    "#Get predictions for explanatory test data\n",
    "original_y_target_predictions = best_estimator.predict(x_explanatory_test)\n",
    "\n",
    "accuracy_report = accuracy_score(y_target_test, original_y_target_predictions)\n",
    "print(f'Best Decision Tree Accuracy Report Score: {accuracy_report}')\n",
    "\n",
    "original_y_prediction_probabilities = best_estimator.predict_proba(x_explanatory_test)[:,1]\n",
    "\n",
    "#compute Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)\n",
    "original_roc_auc = roc_auc_score(y_target_test, original_y_prediction_probabilities)\n",
    "print(f'ROC AUC Score: {original_roc_auc}')\n",
    "\n",
    "best_estimator_parameters = best_estimator.get_params()\n",
    "max_depth = best_estimator_parameters['max_depth']\n",
    "min_samples_leaf = best_estimator_parameters['min_samples_leaf']\n",
    "\n",
    "print(f'Calculated max_depth: [{max_depth}]')\n",
    "print(f'Calculated min_sample_leaf: [{min_samples_leaf}]')\n",
    "#print(best_estimator)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T23:12:33.053894Z",
     "end_time": "2023-04-30T23:12:39.864516Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Hyperparameter Tuning Results:\n",
    "\n",
    "Cross-validation was performed using [`GridSearchCV`](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html) to run through a grid of options for *'max_depth'* and *'min_samples_leaf'*. This process resulted in a *'max_depth'* of 3 and a *'min_samples_leaf'* of 0.04. The Test Accuracy Score was 0.98 (99%) and the AUC score was at 0.998 (99%), which is similar accuracies that happened in D208 Regression models and D209 Task 1 *k-nearest Neighbor* (KNN) models.\n",
    "\n",
    "Even though the model has very successful scores, I am interested in applying a boost to see if it can edge up anymore of if this would actually harm its ability at making predictions."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "#Hyperparameter tuning for the Gradient Boosting Regressor\n",
    "ada_parameters = {\n",
    "    'n_estimators': np.arange(100, 301, 50),\n",
    "    'learning_rate': np.arange(.1, 1.5, .1)\n",
    "}\n",
    "\n",
    "tuned_decision_tree = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=SEED)\n",
    "original_gradient_boosting_regressor = AdaBoostClassifier(base_estimator=tuned_decision_tree, random_state=SEED)\n",
    "\n",
    "#n_jobs controls the amount of parallel processing, and -1 uses ALL available CPU cores to process.\n",
    "cross_validation_ada = GridSearchCV(estimator=original_gradient_boosting_regressor,\n",
    "                                    param_grid=ada_parameters,\n",
    "                                    scoring='roc_auc',\n",
    "                                    cv=5,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "cross_validation_ada.fit(x_explanatory_training, y_target_training)\n",
    "n_estimators = cross_validation_ada.best_params_['n_estimators']\n",
    "learning_rate = cross_validation_ada.best_params_['learning_rate']\n",
    "\n",
    "print(f'GBT best n_estimators: [{n_estimators}]')\n",
    "print(f'GBT best learning_rate: [{learning_rate}]')\n",
    "\n",
    "tuned_ada_booster = AdaBoostClassifier(base_estimator=tuned_decision_tree, n_estimators=n_estimators, learning_rate=learning_rate, random_state=SEED)\n",
    "tuned_ada_booster.fit(x_explanatory_training, y_target_training)\n",
    "\n",
    "tuned_y_target_predictions = tuned_ada_booster.predict(x_explanatory_test)\n",
    "\n",
    "#Evaluate the results\n",
    "tuned_ada_boosted_accuracy_score = accuracy_score(y_target_test, tuned_y_target_predictions)\n",
    "print(f'Ada boosted Decision Tree Model Accuracy: [{tuned_ada_boosted_accuracy_score}]')\n",
    "\n",
    "#Calculate the probabilities of getting a positive class\n",
    "tuned_ada_boosted_y_target_prediction_probabilities = tuned_ada_booster.predict_proba(x_explanatory_test)[:,1]\n",
    "\n",
    "tuned_ada_roc_auc = roc_auc_score(y_target_test, tuned_ada_boosted_y_target_prediction_probabilities)\n",
    "\n",
    "true_negative, false_positive, false_negative, true_positive = confusion_matrix(y_target_test, tuned_y_target_predictions).ravel()\n",
    "mse = MSE(y_target_test, tuned_y_target_predictions)\n",
    "r_mse = mse ** .5\n",
    "c_report = classification_report(y_target_test, tuned_y_target_predictions)\n",
    "\n",
    "c_matrix = f'''| {' ':22} | {'Predicted: No Readmission':^5} | {'Predicted: Readmission':^5} |\\n\n",
    "        |{'':->24}|{'':->27}|{'':->24}|\\n\n",
    "        | {'Actual: No Readmission':^5} | {true_negative:^25} | {false_positive:^22} |\\n\n",
    "        | {'Actual: Readmission':22} | {false_negative:^25} | {true_positive:^22} |\\n\n",
    "        |{'':->24}|{'':->27}|{'':->24}|\\n'''\n",
    "\n",
    "display_confusion_matrix = textwrap.fill(c_matrix, width=80)\n",
    "\n",
    "print(display_confusion_matrix)\n",
    "print(f'Mean Squared Error: {mse}\\n')\n",
    "print(f'Rooted Mean Squared Error: {r_mse}\\n')\n",
    "print(c_report, '\\n')\n",
    "print(f'AUC (Area Under the Curve) Score: {tuned_ada_roc_auc}')\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_target_test, tuned_y_target_predictions)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='Decision Tree (Ada Boost)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree (Ada Boost) ROC Curve')\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-30T23:12:39.864331Z",
     "end_time": "2023-04-30T23:14:51.058911Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"classification-analysis-code\"></a>\n",
    "# D3: Classification Analysis Code\n",
    "\n",
    "##### Note: Because the assignment paper was done entirely within the [`Jupyter Notebook`](https://jupyter.org/) the D2 answer code is pasted here again but only as [`Markdown`](https://www.markdownguide.org/) as to not have the code execute twice.\n",
    "\n",
    "```python\n",
    "#Hyper Paramter Tuning for Decision Tree and Estimator\n",
    "dt_parameters = {\n",
    "    'min_samples_leaf': np.arange(.04, .24, .02),\n",
    "    'max_depth': np.arange(1, 21, 1)\n",
    "}\n",
    "#print(f'Parameter Grid: {dt_parameters}')\n",
    "\n",
    "decision_tree_estimator = DecisionTreeClassifier(random_state=SEED)\n",
    "\n",
    "#n_jobs controls the amount of parallel processing that can be done. Setting this to -1 means ALL available CPU cores will be used.\n",
    "cross_validation_dt = GridSearchCV(estimator=decision_tree_estimator,\n",
    "                                   param_grid= dt_parameters,\n",
    "                                   scoring='roc_auc',\n",
    "                                   cv=5,\n",
    "                                   n_jobs=-1)\n",
    "\n",
    "cross_validation_dt.fit(x_explanatory_training, y_target_training)\n",
    "\n",
    "#Get best estimator\n",
    "best_estimator = cross_validation_dt.best_estimator_\n",
    "\n",
    "#Check Best Estimator Test Accuracy Score\n",
    "best_estimator_test_accuracy = best_estimator.score(x_explanatory_test, y_target_test)\n",
    "print(f'Best Estimator Test Accuracy Score: {best_estimator_test_accuracy}')\n",
    "\n",
    "#Get predictions for explanatory test data\n",
    "original_y_target_predictions = best_estimator.predict(x_explanatory_test)\n",
    "\n",
    "accuracy_report = accuracy_score(y_target_test, original_y_target_predictions)\n",
    "print(f'Best Decision Tree Accuracy Report Score: {accuracy_report}')\n",
    "\n",
    "original_y_prediction_probabilities = best_estimator.predict_proba(x_explanatory_test)[:,1]\n",
    "\n",
    "#compute Receiver Operating Characteristic (ROC) and Area Under the Curve (AUC)\n",
    "original_roc_auc = roc_auc_score(y_target_test, original_y_prediction_probabilities)\n",
    "print(f'ROC AUC Score: {original_roc_auc}')\n",
    "\n",
    "best_estimator_parameters = best_estimator.get_params()\n",
    "max_depth = best_estimator_parameters['max_depth']\n",
    "min_samples_leaf = best_estimator_parameters['min_samples_leaf']\n",
    "\n",
    "print(f'Calculated max_depth: [{max_depth}]')\n",
    "print(f'Calculated min_sample_leaf: [{min_samples_leaf}]')\n",
    "#print(best_estimator)\n",
    "\n",
    "#Hyperparameter tuning for the Gradient Boosting Regressor\n",
    "ada_parameters = {\n",
    "    'n_estimators': np.arange(100, 301, 50),\n",
    "    'learning_rate': np.arange(.1, 1.5, .1)\n",
    "}\n",
    "\n",
    "tuned_decision_tree = DecisionTreeClassifier(max_depth=max_depth, min_samples_leaf=min_samples_leaf, random_state=SEED)\n",
    "original_gradient_boosting_regressor = AdaBoostClassifier(base_estimator=tuned_decision_tree, random_state=SEED)\n",
    "\n",
    "#n_jobs controls the amount of parallel processing, and -1 uses ALL available CPU cores to process.\n",
    "cross_validation_ada = GridSearchCV(estimator=original_gradient_boosting_regressor,\n",
    "                                    param_grid=ada_parameters,\n",
    "                                    scoring='roc_auc',\n",
    "                                    cv=5,\n",
    "                                    n_jobs=-1)\n",
    "\n",
    "cross_validation_ada.fit(x_explanatory_training, y_target_training)\n",
    "n_estimators = cross_validation_ada.best_params_['n_estimators']\n",
    "learning_rate = cross_validation_ada.best_params_['learning_rate']\n",
    "\n",
    "print(f'GBT best n_estimators: [{n_estimators}]')\n",
    "print(f'GBT best learning_rate: [{learning_rate}]')\n",
    "\n",
    "tuned_ada_booster = AdaBoostClassifier(base_estimator=tuned_decision_tree, n_estimators=n_estimators, learning_rate=learning_rate, random_state=SEED)\n",
    "tuned_ada_booster.fit(x_explanatory_training, y_target_training)\n",
    "\n",
    "tuned_y_target_predictions = tuned_ada_booster.predict(x_explanatory_test)\n",
    "\n",
    "#Evaluate the results\n",
    "tuned_ada_boosted_accuracy_score = accuracy_score(y_target_test, tuned_y_target_predictions)\n",
    "print(f'Ada boosted Decision Tree Model Accuracy: [{tuned_ada_boosted_accuracy_score}]')\n",
    "\n",
    "#Calculate the probabilities of getting a positive class\n",
    "tuned_ada_boosted_y_target_prediction_probabilities = tuned_ada_booster.predict_proba(x_explanatory_test)[:,1]\n",
    "\n",
    "tuned_ada_roc_auc = roc_auc_score(y_target_test, tuned_ada_boosted_y_target_prediction_probabilities)\n",
    "\n",
    "true_negative, false_positive, false_negative, true_positive = confusion_matrix(y_target_test, tuned_y_target_predictions).ravel()\n",
    "mse = MSE(y_target_test, tuned_y_target_predictions)\n",
    "r_mse = mse ** .5\n",
    "c_report = classification_report(y_target_test, tuned_y_target_predictions)\n",
    "\n",
    "c_matrix = f'''| {' ':22} | {'Predicted: No Readmission':^5} | {'Predicted: Readmission':^5} |\\n\n",
    "        |{'':->24}|{'':->27}|{'':->24}|\\n\n",
    "        | {'Actual: No Readmission':^5} | {true_negative:^25} | {false_positive:^22} |\\n\n",
    "        | {'Actual: Readmission':22} | {false_negative:^25} | {true_positive:^22} |\\n\n",
    "        |{'':->24}|{'':->27}|{'':->24}|\\n'''\n",
    "\n",
    "display_confusion_matrix = textwrap.fill(c_matrix, width=80)\n",
    "\n",
    "print(display_confusion_matrix)\n",
    "print(f'Mean Squared Error: {mse}\\n')\n",
    "print(f'Rooted Mean Squared Error: {r_mse}\\n')\n",
    "print(c_report, '\\n')\n",
    "print(f'AUC (Area Under the Curve) Score: {tuned_ada_roc_auc}')\n",
    "\n",
    "false_positive_rate, true_positive_rate, thresholds = roc_curve(y_target_test, tuned_y_target_predictions)\n",
    "plt.plot([0,1], [0,1], 'k--')\n",
    "plt.plot(false_positive_rate, true_positive_rate, label='Decision Tree (Ada Boost)')\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Decision Tree (Ada Boost) ROC Curve')\n",
    "plt.show()\n",
    "```\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"accuracy-of-classification-model\"></a>\n",
    "# E1: Accuracy of Classification Model\n",
    "\n",
    "The model is exceptional at predicting whether a patient will be readmitted to the hospital or not. It makes correct predictions about 98% of the time. [The Mean Squared Error (MSE)](https://en.wikipedia.org/wiki/Mean_squared_error) is a measure of how much the model's predictions differ from the actual outcomes, and a low MSE of 0.018 *(1.8%)* indicates that the model's predictions are close to the true outcomes."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"model-results\"></a>\n",
    "# E2: Model Results\n",
    "\n",
    "###### **High Accuracy:**\n",
    "The [model's accuracy](https://www.datarobot.com/wiki/accuracy/#:~:text=Machine%20learning%20model%20accuracy%20is%20the%20measurement%20used,produce%2C%20which%20in%20turn%20deliver%20more%20business%20value.) of 98.2% indicates that it is highly effective at predicting patient readmission status. This means that the model is able to correctly classify the majority of patients into the appropriate categories of \"Readmission\" or \"No Readmission.\" As a result, the model could be a valuable tool for healthcare providers to identify patients at risk of readmission and take preventive measures.\n",
    "<br/>\n",
    "###### **Low Error:**\n",
    "The model's [Mean Squared Error (MSE)](https://en.wikipedia.org/wiki/Mean_squared_error) of 0.018 (1.8%) is low, suggesting that the model's predictions are generally close to the true outcomes. A low MSE indicates that the model is reliable and that its predictions can be trusted for decision-making purposes.\n",
    "<br/>\n",
    "###### **Potential for Improved Patient Care:**\n",
    "The model's strong predictive performance could have practical implications for patient care. By accurately identifying patients who are likely to be readmitted, healthcare providers can implement targeted interventions to address the factors contributing to readmission risk. This could lead to improved patient outcomes, reduced hospital readmission, and more efficient use of healthcare resources.\n",
    "<br/>\n",
    "##### **ROC Curve:**\n",
    "\n",
    "The point of the *ROC Curve* is to see how far away from the diagonal line we can get in the positive direction. This is because the diagonal line represents the 50% correct classification rate, where complete randomness would hover around this line. If the classification line falls below the diagonal line, it's a poor model, and if it goes above the diagonal line, it's a better model. We can see that this model is about as close to 1.0 as it can get."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"classification-limitation\"></a>\n",
    "# E3: Classification Limitation\n",
    "\n",
    "A limitation of the [`Decision Tree Classifier`](https://en.wikipedia.org/wiki/Decision_tree_learning) is outliers. These can drag attention to instances that are wrongly predicted causing over-fitting. To help mitigate the issues brought on by outliers/static noise, we deployed [`AdaBoost: Training`](https://en.wikipedia.org/wiki/AdaBoost). This ensemble learning algorithm through its process will change the weights of the weakly predicted items to help correct the branch and leaf generation for the decision tree increasing its accuracy."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"recommended-action\"></a>\n",
    "# E4: Recommended Action\n",
    "\n",
    "The recommendation is to implementation the model into the hospital practice. Given the strong performance of the model, the hospital may consider implementing it as a decision support tool to help identify patients at risk of readmission. This could enable targeted interventions to reduce the likelihood of readmission and improve patient outcomes. Clinical judgment and patient preferences should always be taken into account when making decisions about patient care. This is because the model is a tool for the tool belt and not and end all be all type of tool."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"panopto-recording\"></a>\n",
    "# F: Panopto Recording\n",
    "\n",
    "Summary of Environments:\n",
    "  * OS: Windows 11 + macOS Ventura (I work in both environments)\n",
    "  * Language: Python\n",
    "  * Environment: Jupyter Notebook through JetBrains DataSpell IDE (Cross-Platform)\n",
    "\n",
    "[D209 - Panopto Recording](https://wgu.hosted.panopto.com/Panopto/Pages/Viewer.aspx?id=aa2965e2-07a8-412c-9663-aff500683585)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"code-references\"></a>\n",
    "# G: Code References"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"source-references\"></a>\n",
    "# H: Source References"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Citations\n",
    " * Bruce, P., Bruce, A., & Gedeck, P. (2019). Practical Statistics for Data Scientists: 50 Essential Concepts. O'Reilly Media, Inc.\n",
    " * MyGreatLearning. (n.d.). Decision Tree Algorithm. Retrieved April 23, 2023, from https://www.mygreatlearning.com/blog/decision-tree-algorithm/#:~:text=Despite%20such%20simplicity%20of%20a%20decision%20tree%2C%20it,recursive%20manner%20on%20the%20basis%20of%20attribute%20values."
   ],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
