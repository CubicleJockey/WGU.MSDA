{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# D209 Data Mining I Performance Assessment - Task 2\n",
    "### NVM2 — NVM2 Task 2: Predictive Analysis\n",
    "#### Data Mining I — D209\n",
    "#### PRFA — NVM2\n",
    "> André Davis\n",
    "> StudentID: 010630641\n",
    "> MSDA\n",
    ">\n",
    "> Competencies\n",
    "> 4030.06.1 : Classification Data Mining Models\n",
    ">   The graduate applies observations to appropriate classes and categories using classification models.\n",
    ">\n",
    "> 4030.06.3 : Data Mining Model Performance\n",
    ">   The graduate evaluates data mining model performance for precision, accuracy, and model comparison.\n",
    "\n",
    "#### Table of Contents\n",
    "<ul>\n",
    "    <li><a href=\"#research-question\">A1: Research Question</li>\n",
    "    <li><a href=\"#goal-of-analysis\">A2: Objectives and Goals of Analysis</a></li>\n",
    "    <li><a href=\"#justification\">B1: Justification of Classification Method</a></li>\n",
    "    <li><a href=\"#assumption-of-classification\">B2: Assumptions of a Classification Model</a></li>\n",
    "    <li><a href=\"#packages-and-analysis-support\">B3: Benefits of Chosen Tools</a></li>\n",
    "    <li><a href=\"#data-preparation-goals\">C1: Data Preparation Goals and Necessary Manipulation</a></li>\n",
    "    <li><a href=\"#variable-selection-and-identification\">C2: Variable Selection \\& Identification</a></li>\n",
    "    <li><a href=\"#data-preparation\">C3: Preparation of Data</a></li>\n",
    "    <li><a href=\"#copy-of-prepared-data\">C4: Copy of Prepared Data Set</a></li>\n",
    "    <li><a href=\"#data-splitting-and-copying\">D1: Data Splitting, Copy of Split Data</a></li>\n",
    "    <li><a href=\"#analysis-description\">D2: Analysis Description</a></li>\n",
    "    <li><a href=\"#classification-analysis-code\">D3: Classification Analysis Code</a></li>\n",
    "    <li><a href=\"#accuracy-of-classification-model\">E1: Accuracy of Classification Model</a></li>\n",
    "    <li><a href=\"#model-results\">E2: Model Results</a></li>\n",
    "    <li><a href=\"#classification-limitations\">E3: Classification Limitations</a></li>\n",
    "    <li><a href=\"#recommended-action\">E4: Recommended Action</a></li>\n",
    "    <li><a href=\"#panopto-recording\">F: Panopto Recording</a></li>\n",
    "    <li><a href=\"#code-references\">G: Code References</a></li>\n",
    "    <li><a href=\"#source-references\">H: Source References</a></li>\n",
    "</ul>"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"research-question\"></a>\n",
    "# A1: Research Question\n",
    "\n",
    "*Answer your question using one of the following methods:* [`Decision Tree`](https://scikit-learn.org/stable/modules/tree.html), [`Random Forest`](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html), [`Advanced Refression - Lasso`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html), or [`Advanced Regression - Ridge`](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html)\n",
    "\n",
    "In D208 Task 2 (Logistical Regression) and D209 Task 1 (Classification Analysis - k-nearest neighbor (KNN) I've been attempting to get the best model for answering `\"Which factors have a significant effect on readmission?\"` So far I've approached this question 2 different ways and have come up with pretty reasonable models with high accuracy and lost MSE *(Means Squared Error)*.\n",
    "\n",
    "I am going to attempt to generate a better model for predicting readmission using the `Decision Tree` method."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"objectives-and-goals\"></a>\n",
    "# A2: Objective and Goals of Analysis\n",
    "\n",
    "Because *D208 (Logical Regression)* and *D209 Task 1 - (Classification: k-nearest neighbor)* both had accuracies in the neighborhood of *0.97 (97%)* and *0.98 (8%)*. The objective is to answer A1: Question of `\"Which factors have a significant effect on readmission?\"` while the goal of this method of `Decision Tree` is to meet the same level of accuracy but bring easier interpretation with a method that can handle categorical and numerical data with complex relationships."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"justification\"></a>\n",
    "# B1: Justification of Classification Method\n",
    "\n",
    "Because the [Logistics Regression](https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html) and [k-nearest Neighbor (KNN)](https://scikit-learn.org/stable/modules/generated/sklearn.neighbors.KNeighborsClassifier.html) both had high accuracy and low MSE values, I wanted a model that could increase understandability. A decision tree out of the choices listed for A1 met these criteria.\n",
    "\n",
    "A `Decision Tree` is similar to a flowchart for making choices. A decision tree is a graphical representation of a decision-making process that helps in identifying the possible outcomes given a series of related choices. Visually, when given a data point, it starts at a root node and branches out into various possible outcomes or paths based on the decisions made at each node. Each decision is represented by a branch, and each outcome is represented by a leaf node.\n",
    "\n",
    "Another way to say this is that \"A tree model is a set of \"if-then-else\" rules that are easy to understand and to implement.\" (Bruce, P., Bruce, A., & Gedeck, P.  2019 p.250)\n",
    "\n",
    "Because of its flowchart appearance this makes `Decision Tree` easy to understand and interpret. Because of this easy visualization, it makes communicating a complex decision-making process to everyone in a team accessible."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"classification-model\"></a>\n",
    "# B2: Assumptions of a Classification Model\n",
    "\n",
    "Assumptions:\n",
    "\n",
    " * Features are independent of each other.\n",
    " * Classes used are balanced\n",
    " * Non-linear relationships between input and output variables.\n",
    " * \"Discretion of continuous variables is required.\" (MyGreatLearning, n.d.)\n",
    " * \"The data taken for training should be wholly considered as root\" (MyGreatLearning, n.d.)\n",
    " * \"Distribution of records is done in a recursive manner on the basis of attribute values.\" (MyGreatLearning, n.d.)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"packages-and-analysis-support\"></a>\n",
    "# B3: List Packages & Support of Analysis\n",
    "\n",
    "#### Analytic package for Python:\n",
    " * **Data manipulation:**\n",
    "    * [Pandas](https://pandas.pydata.org/docs/)\n",
    "      - Pandas library is used for data manipulation, analysis, and cleaning. Pandas' main data structures are the Series (1-dimensional) and DataFrame (2-dimensional).\n",
    "          - [Version 2](https://towardsdatascience.com/whats-new-in-pandas-2-0-5df366eb0197) is coming soon and will replace NumPy with Apache Arrows.\n",
    "    * [NumPy](https://numpy.org/doc/)\n",
    "         - Library used for numerical computing. It provides support for multidimensional arrays, matrices, and high-level mathematical functions to perform complex computations quickly and efficiently.\n",
    " * **Displaying Data:**\n",
    "    * [MatPlotLib](https://matplotlib.org/)\n",
    "        * This is a data visualization library.\n",
    " * **Analysis:**\n",
    "    * SkLearn (Scikit-learn - Machine Learning):\n",
    "        * [train_test_split](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)\n",
    "        * [preprocessing](https://scikit-learn.org/stable/modules/preprocessing.html)\n",
    "        * [DecisionTreeClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html)\n",
    "        * [AdaBoostClassifier](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.AdaBoostClassifier.html)\n",
    "        * [GridSearchCV](https://scikit-learn.org/stable/modules/generated/sklearn.model_selection.GridSearchCV.html)\n",
    "        * [confusion_matrix](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.confusion_matrix.html)\n",
    "        * [roc_auc_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_auc_score.html)\n",
    "        * [roc_curve](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.roc_curve.html)\n",
    "        * [classification_report](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.classification_report.html)\n",
    "        * [accuracy_score](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.accuracy_score.html)\n",
    "        * [mean_squared_error](https://scikit-learn.org/stable/modules/generated/sklearn.metrics.mean_squared_error.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 10000 entries, 1 to 10000\n",
      "Data columns (total 49 columns):\n",
      " #   Column              Non-Null Count  Dtype  \n",
      "---  ------              --------------  -----  \n",
      " 0   Customer_id         10000 non-null  object \n",
      " 1   Interaction         10000 non-null  object \n",
      " 2   UID                 10000 non-null  object \n",
      " 3   City                10000 non-null  object \n",
      " 4   State               10000 non-null  object \n",
      " 5   County              10000 non-null  object \n",
      " 6   Zip                 10000 non-null  int64  \n",
      " 7   Lat                 10000 non-null  float64\n",
      " 8   Lng                 10000 non-null  float64\n",
      " 9   Population          10000 non-null  int64  \n",
      " 10  Area                10000 non-null  object \n",
      " 11  TimeZone            10000 non-null  object \n",
      " 12  Job                 10000 non-null  object \n",
      " 13  Children            10000 non-null  int64  \n",
      " 14  Age                 10000 non-null  int64  \n",
      " 15  Income              10000 non-null  float64\n",
      " 16  Marital             10000 non-null  object \n",
      " 17  Gender              10000 non-null  object \n",
      " 18  ReAdmis             10000 non-null  object \n",
      " 19  VitD_levels         10000 non-null  float64\n",
      " 20  Doc_visits          10000 non-null  int64  \n",
      " 21  Full_meals_eaten    10000 non-null  int64  \n",
      " 22  vitD_supp           10000 non-null  int64  \n",
      " 23  Soft_drink          10000 non-null  object \n",
      " 24  Initial_admin       10000 non-null  object \n",
      " 25  HighBlood           10000 non-null  object \n",
      " 26  Stroke              10000 non-null  object \n",
      " 27  Complication_risk   10000 non-null  object \n",
      " 28  Overweight          10000 non-null  object \n",
      " 29  Arthritis           10000 non-null  object \n",
      " 30  Diabetes            10000 non-null  object \n",
      " 31  Hyperlipidemia      10000 non-null  object \n",
      " 32  BackPain            10000 non-null  object \n",
      " 33  Anxiety             10000 non-null  object \n",
      " 34  Allergic_rhinitis   10000 non-null  object \n",
      " 35  Reflux_esophagitis  10000 non-null  object \n",
      " 36  Asthma              10000 non-null  object \n",
      " 37  Services            10000 non-null  object \n",
      " 38  Initial_days        10000 non-null  float64\n",
      " 39  TotalCharge         10000 non-null  float64\n",
      " 40  Additional_charges  10000 non-null  float64\n",
      " 41  Item1               10000 non-null  int64  \n",
      " 42  Item2               10000 non-null  int64  \n",
      " 43  Item3               10000 non-null  int64  \n",
      " 44  Item4               10000 non-null  int64  \n",
      " 45  Item5               10000 non-null  int64  \n",
      " 46  Item6               10000 non-null  int64  \n",
      " 47  Item7               10000 non-null  int64  \n",
      " 48  Item8               10000 non-null  int64  \n",
      "dtypes: float64(7), int64(15), object(27)\n",
      "memory usage: 3.8+ MB\n"
     ]
    }
   ],
   "source": [
    "import textwrap\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, classification_report, accuracy_score, mean_squared_error\n",
    "\n",
    "\n",
    "#load the data ignoring the first column as it's simply an index\n",
    "medical_data = pd.read_csv('./Data/Medical/medical_clean.csv', index_col=0)\n",
    "medical_data.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:59:06.869852Z",
     "end_time": "2023-04-23T23:59:06.956247Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-preparation-goals\"></a>\n",
    "# C1: Data Preparation Goals and Necessary Manipulation\n",
    "\n",
    " * D209 - *Data Mining I* is continuation of datasets from *D206 - Data Cleaning* and is given to us pre-cleaned to a point. Listed below are items pre-completed:\n",
    "     * Detecting Duplicates\n",
    "     * Dealing with missing values\n",
    "     * Detecting Outliers\n",
    " * Hot Encoding (*Dummy Variables* or *Indicator Variables*)\n",
    "     * \"Is a process by which categorical variables are converted into a form that could be provided to ML algorithms to do a better job in prediction.\" (Vasudev, 2017).\n",
    "     * \"Binary 0-1 variables derived by recoding factor data for use in regression and other models\" (Bruce, P., Bruce, A., & Gedeck, P.  2019 p.163)\n",
    "     * If you have a Series that has 3 categorical levels you can split your series into two variables to represent the three states. If you have blue, yellow, and black and convert them to 1/0's then you only need two columns for the 3 series. For example if you have yellow = 0, and black = 0 then that means your value is blue without having that datapoint. We can apply this to the `Complication Risk` series in the dataset. It includes Low, Medium, and High. If we use the High (Series) and the Low (Series) it can be assumed if High and Low are both 0 values then the value represented is Medium.\n",
    "     * Pandas function for Hot-Encoding is `pd.get_dummies(data)` documentation is [here](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.get_dummies.html)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"variable-selection-and-identification\"></a>\n",
    "# C2: Variable Selection & Identification\n",
    "\n",
    "I am continuing on with the question from D208 so my variables are going to be reused to see if we can get better results with the *k-nearest neighbor (KNN)* model. Below are the variables that were used during logistic regression. Like before survey and census data was not relevant when looking for explanatory variables that were significant to readmission's (`ReAdmin`) to the hospital.\n",
    "\n",
    "| Data Type    | Variable                              |\n",
    "|--------------|---------------------------------------|\n",
    "| Continuous   | \tNumber of Children                   |\n",
    "| Continuous   | \tVitamin D levels                     |\n",
    "| Continuous   | \tNumber of Dr Visits                  |\n",
    "| Continuous   | \tNumber of Vitamin D supplements      |\n",
    "| Continuous   | \tFull meals                           |\n",
    "| Categorical  | Area (Rural, Suburban, Urban)         |\n",
    "| Categorical  | Gender (Male, Female, Nonbinary)      |\n",
    "| Categorical  | Readmission                           |\n",
    "| Categorical  | Soft Drink Consumption                |\n",
    "| Categorical  | Initial Admission Reason              |\n",
    "| Categorical  | High Blood Pressure                   |\n",
    "| Categorical  | Stroke                                |\n",
    "| Categorical  | Complication Risk (Low, Medium, High) |\n",
    "| Categorical  | Overweight                            |\n",
    "| Categorical  | Arthritis                             |\n",
    "| Categorical  | \tDiabetes                             |\n",
    "| Categorical  | \tHyperlipidemia                       |\n",
    "| Categorical  | \tAnxiety                              |\n",
    "| Categorical  | \tAllergic Rhinitis                    |\n",
    "| Categorical\t | Asthma                                |\n",
    "| Categorical\t | Days hospitalized                     |"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-preparation\"></a>\n",
    "# C3: Preparation of Data\n",
    "\n",
    "NOTE: `Decision Tree` is not sensitive to outliers and nor does it require normalization. These actions are not performed."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Medical data does NOT contain any missing values\n",
      "\n",
      "Categoricals with high cardinality to be removed:\n",
      "['Services', 'Timely_Admission', 'Timely_Treatment', 'Timely_Visits', 'Reliability', 'Options', 'Hours_Of_Treatment', 'Courteous_Staff', 'Listening']\n",
      "\n",
      "\n",
      "Categoricals remaining:\n",
      "['Gender', 'ReAdmis', 'Soft_drink', 'Initial_admin', 'HighBlood', 'Stroke', 'Complication_risk', 'Overweight', 'Arthritis', 'Diabetes', 'Hyperlipidemia', 'BackPain', 'Anxiety', 'Allergic_rhinitis', 'Reflux_esophagitis', 'Asthma']\n",
      "\n",
      "\n",
      "Review Each Data Series\n",
      "\n",
      "count    10000.000000\n",
      "mean         2.097200\n",
      "std          2.163659\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%          3.000000\n",
      "max         10.000000\n",
      "Name: Children, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean        53.511700\n",
      "std         20.638538\n",
      "min         18.000000\n",
      "25%         36.000000\n",
      "50%         53.000000\n",
      "75%         71.000000\n",
      "max         89.000000\n",
      "Name: Age, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean        17.964262\n",
      "std          2.017231\n",
      "min          9.806483\n",
      "25%         16.626439\n",
      "50%         17.951122\n",
      "75%         19.347963\n",
      "max         26.394449\n",
      "Name: VitD_levels, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.409000\n",
      "std          0.491674\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: HighBlood, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.709400\n",
      "std          0.454062\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: Overweight, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.357400\n",
      "std          0.479258\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: Arthritis, dtype: float64\n",
      "\n",
      "count    10000.00000\n",
      "mean         0.27380\n",
      "std          0.44593\n",
      "min          0.00000\n",
      "25%          0.00000\n",
      "50%          0.00000\n",
      "75%          1.00000\n",
      "max          1.00000\n",
      "Name: Diabetes, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.411400\n",
      "std          0.492112\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: BackPain, dtype: float64\n",
      "\n",
      "count    10000.00000\n",
      "mean         0.28930\n",
      "std          0.45346\n",
      "min          0.00000\n",
      "25%          0.00000\n",
      "50%          0.00000\n",
      "75%          1.00000\n",
      "max          1.00000\n",
      "Name: Asthma, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean        34.455299\n",
      "std         26.309341\n",
      "min          1.001981\n",
      "25%          7.896215\n",
      "50%         35.836244\n",
      "75%         61.161020\n",
      "max         71.981490\n",
      "Name: Initial_days, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.366900\n",
      "std          0.481983\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: ReAdmis, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.451700\n",
      "std          0.497687\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: complication_risk_medium, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.212500\n",
      "std          0.409097\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: complication_risk_low, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.506000\n",
      "std          0.499989\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          1.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: initial_admission_emergency, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.243600\n",
      "std          0.429276\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: initial_admission_observation, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.476800\n",
      "std          0.499486\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          1.000000\n",
      "max          1.000000\n",
      "Name: gender_male, dtype: float64\n",
      "\n",
      "count    10000.000000\n",
      "mean         0.021400\n",
      "std          0.144721\n",
      "min          0.000000\n",
      "25%          0.000000\n",
      "50%          0.000000\n",
      "75%          0.000000\n",
      "max          1.000000\n",
      "Name: gender_non_binary, dtype: float64\n",
      "\n"
     ]
    }
   ],
   "source": [
    "original_medical = medical_data #storing backup of original data incase it's needed\n",
    "#del medical_clean_data[medical_clean_data.columns[0]]\n",
    "\n",
    "any_missing_values = medical_data.isna().values.any()\n",
    "if not any_missing_values:\n",
    "    print('Medical data does NOT contain any missing values\\n')\n",
    "else:\n",
    "    print('Medical data CONTAINS missing values.\\n')\n",
    "\n",
    "column_renames = {\n",
    "    'Item1': 'Timely_Admission'\n",
    "    ,'Item2': 'Timely_Treatment'\n",
    "    ,'Item3': 'Timely_Visits'\n",
    "    ,'Item4': 'Reliability'\n",
    "    ,'Item5': 'Options'\n",
    "    ,'Item6': 'Hours_Of_Treatment'\n",
    "    ,'Item7': 'Courteous_Staff'\n",
    "    ,'Item8': 'Listening' #Evidence of active listening from Doctor\n",
    "}\n",
    "medical_data.rename(columns=column_renames, inplace=True)\n",
    "#medical_clean_data\n",
    "\n",
    "removal_attributes = ['Customer_id', 'Interaction', 'UID',\n",
    "                      'Zip', 'Lat', 'Lng', 'City', 'State', 'County',\n",
    "                      'Area', 'Job', 'Marital', 'Population', 'TimeZone']\n",
    "\n",
    "medical_clean_data = medical_data.drop(columns=removal_attributes)\n",
    "\n",
    "category_dtype = 'category'\n",
    "convert_to_category = {\n",
    "    'Gender': category_dtype,\n",
    "    'ReAdmis': category_dtype,\n",
    "    'Soft_drink': category_dtype,\n",
    "    'Initial_admin': category_dtype,\n",
    "    'HighBlood': category_dtype,\n",
    "    'Stroke': category_dtype,\n",
    "    'Complication_risk': category_dtype,\n",
    "    'Overweight': category_dtype,\n",
    "    'Arthritis': category_dtype,\n",
    "    'Diabetes': category_dtype,\n",
    "    'Hyperlipidemia': category_dtype,\n",
    "    'BackPain': category_dtype,\n",
    "    'Anxiety': category_dtype,\n",
    "    'Allergic_rhinitis': category_dtype,\n",
    "    'Reflux_esophagitis': category_dtype,\n",
    "    'Asthma': category_dtype,\n",
    "    'Services': category_dtype,\n",
    "    'Timely_Admission': category_dtype,\n",
    "    'Timely_Treatment': category_dtype,\n",
    "    'Timely_Visits': category_dtype,\n",
    "    'Reliability': category_dtype,\n",
    "    'Options': category_dtype,\n",
    "    'Hours_Of_Treatment': category_dtype,\n",
    "    'Courteous_Staff': category_dtype,\n",
    "    'Listening': category_dtype\n",
    "}\n",
    "\n",
    "medical_clean_data = medical_clean_data.astype(convert_to_category)\n",
    "\n",
    "#Logical categorical variables converted to numerical\n",
    "columns_to_reexpress = ['ReAdmis', 'Soft_drink', 'HighBlood', 'Stroke',\n",
    "                        'Overweight', 'Arthritis', 'Diabetes', 'Hyperlipidemia',\n",
    "                        'BackPain', 'Anxiety', 'Allergic_rhinitis', 'Reflux_esophagitis',\n",
    "                        'Asthma']\n",
    "for column in columns_to_reexpress:\n",
    "    medical_clean_data[column] = medical_clean_data[column].map({'Yes': 1, 'No': 0 }).astype(np.int64)\n",
    "\n",
    "categorical_medical_data = medical_clean_data[convert_to_category.keys()]\n",
    "high_cardinalities = categorical_medical_data.nunique() > 3 #(> 3-5 Levels)\n",
    "high_cardinalities = high_cardinalities[high_cardinalities == True]\n",
    "high_cardinalities = list(high_cardinalities.index.values)\n",
    "print('Categoricals with high cardinality to be removed:')\n",
    "print(high_cardinalities)\n",
    "print('\\n')\n",
    "\n",
    "medical_clean_data = medical_clean_data.drop(columns=high_cardinalities)\n",
    "\n",
    "low_cardinalities = [item for item in list(convert_to_category.keys()) if item not in high_cardinalities]\n",
    "print('Categoricals remaining:')\n",
    "print(low_cardinalities)\n",
    "print('\\n')\n",
    "\n",
    "#Re-level ordinal/nominal categoricals\n",
    "complication_risk_dummies = pd.get_dummies(data=medical_clean_data['Complication_risk'], drop_first=True)\n",
    "\n",
    "medical_clean_data['complication_risk_medium'] = complication_risk_dummies['Medium']\n",
    "medical_clean_data['complication_risk_low'] = complication_risk_dummies['Low']\n",
    "\n",
    "initial_admission_dummies = pd.get_dummies(data=medical_clean_data['Initial_admin'], drop_first=True)\n",
    "\n",
    "medical_clean_data['initial_admission_emergency'] = initial_admission_dummies['Emergency Admission']\n",
    "medical_clean_data['initial_admission_observation'] = initial_admission_dummies['Observation Admission']\n",
    "\n",
    "gender_dummies = pd.get_dummies(data=medical_clean_data['Gender'], drop_first=True)\n",
    "\n",
    "medical_clean_data['gender_male'] = gender_dummies['Male']\n",
    "medical_clean_data['gender_non_binary'] = gender_dummies['Nonbinary']\n",
    "\n",
    "decision_tree_variables = ['Children', 'Age', 'VitD_levels', 'HighBlood', 'Overweight', 'Arthritis', 'Diabetes', 'BackPain', 'Asthma', 'Initial_days', 'ReAdmis', 'complication_risk_medium', 'complication_risk_low', 'initial_admission_emergency', 'initial_admission_observation', 'gender_male','gender_non_binary']\n",
    "\n",
    "prepared_medical_data = medical_clean_data[decision_tree_variables]\n",
    "\n",
    "print('Review Each Data Series\\n')\n",
    "for column in prepared_medical_data.columns:\n",
    "    current = prepared_medical_data[column]\n",
    "    if np.issubdtype(current.dtype, np.number):\n",
    "        print(f'{current.describe()}\\n')\n",
    "    else:\n",
    "        print(f'{current.value_counts()}\\n')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:59:06.957251Z",
     "end_time": "2023-04-23T23:59:07.099209Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"copy-of-prepared-data\"></a>\n",
    "# C4: Copy of Prepared Data Set"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "copy_of_prepared_medical_data = prepared_medical_data.copy()\n",
    "copy_of_prepared_medical_data.to_csv('./decision-tree-prepared-data.csv')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:59:07.080690Z",
     "end_time": "2023-04-23T23:59:07.154982Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-splitting-and-copying\"></a>\n",
    "# D1: Data Splitting, Copy of Split Data"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "#Split and store dependent (response/target) and independent (explanatory) variables\n",
    "y_target_variable = prepared_medical_data['ReAdmis'].copy()\n",
    "x_explanatory_variables = prepared_medical_data.drop(columns=['ReAdmis']).copy()\n",
    "\n",
    "#Split our data into training and test datasets. We will use the ration of 80% training and 20% test. Stratify will maintain proportions correctly.\n",
    "x_explanatory_training, x_explanatory_test, y_target_training, y_target_test = train_test_split(x_explanatory_variables, y_target_variable, train_size=.8, test_size=.2, random_state=42, stratify=y_target_variable)\n",
    "\n",
    "#Save each file for assessment turn-in\n",
    "x_explanatory_training.to_csv('./x_explanatory-training-dataset-task2.csv')\n",
    "x_explanatory_test.to_csv('./x_explanatory-testing-dataset-task2.csv')\n",
    "\n",
    "y_target_training.to_csv('./y_target-training-dataset-task2.csv')\n",
    "y_target_test.to_csv('./y_target-testing-dataset-task2.csv')\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:59:07.126950Z",
     "end_time": "2023-04-23T23:59:07.205071Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"analysis-description\"></a>\n",
    "# D2: Analysis Description"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"classification-analysis-code\"></a>\n",
    "# D3: Classification Analysis Code"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"accuracy-of-classification-model\"></a>\n",
    "# E1: Accuracy of Classification Model"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"model-results\"></a>\n",
    "# E2: Model Results"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"classification-limitations\"></a>\n",
    "# E3: Classification Limitations"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"recommended-action\"></a>\n",
    "# E4: Recommended Action"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"panopto-recording\"></a>\n",
    "# F: Panopto Recording\n",
    "\n",
    "Summary of Environments:\n",
    "  * OS: Windows 11 + macOS Ventura (I work in both environments)\n",
    "  * Language: Python\n",
    "  * Environment: Jupyter Notebook through JetBrains DataSpell IDE (Cross-Platform)\n",
    "\n",
    "[D209 - Panopto Recording]()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"code-references\"></a>\n",
    "# G: Code References"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"source-references\"></a>\n",
    "# H: Source References"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Citations\n",
    " * Bruce, P., Bruce, A., & Gedeck, P. (2019). Practical Statistics for Data Scientists: 50 Essential Concepts. O'Reilly Media, Inc.\n",
    " * MyGreatLearning. (n.d.). Decision Tree Algorithm. Retrieved April 23, 2023, from https://www.mygreatlearning.com/blog/decision-tree-algorithm/#:~:text=Despite%20such%20simplicity%20of%20a%20decision%20tree%2C%20it,recursive%20manner%20on%20the%20basis%20of%20attribute%20values."
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2023-04-23T23:59:07.205071Z",
     "end_time": "2023-04-23T23:59:07.220613Z"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
