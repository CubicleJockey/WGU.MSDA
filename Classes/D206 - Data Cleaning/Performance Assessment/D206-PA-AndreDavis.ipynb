{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Environment\n",
    "\n",
    " * [Visual Studio Code IDE](https://code.visualstudio.com/?wt.mc_id=DX_841432)\n",
    "   * [Jupyter Extension for Visual Studio Code](https://marketplace.visualstudio.com/items?itemName=ms-toolsai.jupyter)\n",
    "   * [Python v3.9.13](https://www.python.org/downloads/release/python-3913/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Imports\n",
    "\n",
    " * [Pandas](https://pandas.pydata.org/)\n",
    " * [NumPy](https://numpy.org/)\n",
    " * [missingno](https://github.com/ResidentMario/missingno)\n",
    " * [matplotlib](https://matplotlib.org/stable/index.html)\n",
    " * [sys](https://docs.python.org/3/library/sys.html)\n",
    " * [Seaborn](https://seaborn.pydata.org/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import missingno as msno\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import seaborn as sb\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Load data & Consistant Clean-up\n",
    "\n",
    "File: medical_raw_data.csv\n",
    "<br><br>\n",
    "Description:\n",
    "    \n",
    "* 1. Column is an unamed numbered column. We will be skipping this.\n",
    "* 2. Datetypes will be converted to appropriate values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Current Python Version: {sys.version}\")\n",
    "\n",
    "file = './medical_raw_data.csv'\n",
    "\n",
    "use_columns = range(1, 53)  # Skip first column\n",
    "medical_data = pd.read_csv(file, header = 0, usecols = use_columns)\n",
    "\n",
    "convert_to_category = {\n",
    "    'Zip': 'category',\n",
    "    'City': 'category',\n",
    "    'State': 'category',\n",
    "    'County': 'category',\n",
    "    'Area': 'category',\n",
    "    'Timezone': 'category',\n",
    "    'Job': 'category',\n",
    "    'Education': 'category',\n",
    "    'Employment': 'category',\n",
    "    'Marital': 'category',\n",
    "    'Gender': 'category',\n",
    "    'ReAdmis': 'category',\n",
    "    'Soft_drink': 'category',\n",
    "    'Initial_admin': 'category',\n",
    "    'HighBlood': 'category',\n",
    "    'Stroke': 'category',\n",
    "    'Complication_risk': 'category',\n",
    "    'Arthritis': 'category',\n",
    "    'Diabetes': 'category',\n",
    "    'Hyperlipidemia': 'category',\n",
    "    'BackPain': 'category',\n",
    "    'Allergic_rhinitis': 'category',\n",
    "    'Reflux_esophagitis': 'category',\n",
    "    'Asthma': 'category',\n",
    "    'Services': 'category',\n",
    "    'Item1': 'category',\n",
    "    'Item2': 'category',\n",
    "    'Item3': 'category',\n",
    "    'Item4': 'category',\n",
    "    'Item5': 'category',\n",
    "    'Item6': 'category',\n",
    "    'Item7': 'category',\n",
    "    'Item8': 'category'\n",
    "}\n",
    "\n",
    "#update datatype listed in convert_to_category to category datatype\n",
    "medical_data = medical_data.astype(convert_to_category)\n",
    "\n",
    "#these are categorical variables(column) that need to be converted into Yes/No later for data uniformity\n",
    "convert_to_category.update({'Overweight': 'category', 'Anxiety': 'category', })\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Observe the Data Frames Information"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_data.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting Duplicates\n",
    "\n",
    "###### Duplicate detection methods\n",
    "* Detecting duplicates as a row across all columns. \n",
    "  * Pandas provides `pandas.DataFrame.duplicate()` function. This checks if rows are duplicated across all the columns.\n",
    "    * [Documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.duplicated.html)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_columns_duplicates = medical_data.duplicated()\n",
    "print(all_columns_duplicates.value_counts())\n",
    "\n",
    "medical_duplicate_rows = medical_data[all_columns_duplicates]\n",
    "\n",
    "#Assert that we have 0 full row duplicates\n",
    "assert len(medical_duplicate_rows.values) == 0\n",
    "\n",
    "duplicate_customer_ids_groups = medical_data.duplicated(subset = ['Customer_id', 'Interaction', 'UID'])\n",
    "print(duplicate_customer_ids_groups.value_counts())\n",
    "\n",
    "customer_id_duplicate_rows = medical_data[duplicate_customer_ids_groups]\n",
    "\n",
    "#Asset that we do not have any of the 3 customer id types as duplicated\n",
    "assert len(customer_id_duplicate_rows) == 0\n",
    "\n",
    "duplicate_caseorder = medical_data.duplicated(subset = ['CaseOrder'])\n",
    "print(duplicate_caseorder.value_counts())\n",
    "\n",
    "caseorder_duplicates = medical_data[duplicate_caseorder]\n",
    "\n",
    "#Assert that we do not have any duplicated Case Orders\n",
    "assert len(caseorder_duplicates) == 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating Functions To Assist In Missing Data Detection:\n",
    "\n",
    "##### Description:\n",
    "    Becaues each variable (column) get's checked for missing values with the same Data Frame functions [`isna()`, `sum()`] and steps.\n",
    "    There are two functions:\n",
    "    \n",
    "  * **Function:** `checkForMissingValues(series, columnName)`\n",
    "    * This takes a Data Frame series and a specific column and runs Pandas isna() for evaluating the missing values.\n",
    "    * Pandas sum() is then used to get the count of missing data. If that count exceeds 0 messages will be printed to inform that missing values were found and the count returned.\n",
    "  <br>\n",
    "  * **Function:** `checkForMissingValuesByColumns(series, columns)`\n",
    "    * This takes a Data Frame series and a list of column names to check for missing values.\n",
    "    * This function will loop through the list of columns and call `checkForMissingValues` for the result\n",
    "      * After all the columns have been evaluated for missing values a new Data Frame is created that holds Column Name and # of missing values for that column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Creating helper functions for detection of missing data\n",
    "\n",
    "def checkForMissingValues(series: pd.Series, columnName: str):\n",
    "    naCount = 0\n",
    "    try:\n",
    "        naInfo = series[columnName].isna()\n",
    "        naCount = naInfo.sum()\n",
    "        #print(f'{columnName} total missing count: {naCount}\\n')\n",
    "\n",
    "        assert naCount == 0\n",
    "    except AssertionError:\n",
    "        print(f'Missing data detected for {columnName} column of Data Frame')\n",
    "    except:\n",
    "        print(f'Unknown column found {columnName}')\n",
    "    return naCount\n",
    "\n",
    "def checkForMissingValuesByColumns(series, columns=[]):\n",
    "    naCounts = []\n",
    "    for column in columns:\n",
    "        naCount = checkForMissingValues(series, column)\n",
    "        naCounts.append(naCount)\n",
    "\n",
    "    missingValuesResult = {\n",
    "        'Column': columns,\n",
    "        'NA_Count': naCounts\n",
    "    }\n",
    "\n",
    "    naDataFrame = pd.DataFrame(missingValuesResult)\n",
    "\n",
    "    return naDataFrame\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting Missing Values\n",
    "\n",
    "##### Description:\n",
    "\n",
    "We will be using the resulting Data Frame naReport that was generated by our custom function that checked all the columns for missing data. We will retrieve any observation (row) that includes `NA_Count > 0` and store this is a `missing_data` Data Frame to use for the visualization verification of missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('\\nChecking for missing data in each column. \\n')\n",
    "\n",
    "naReport = checkForMissingValuesByColumns(medical_data, medical_data.columns)\n",
    "missing_data = naReport[naReport['NA_Count'] > 0]\n",
    "missing_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Visualizing Missing Data\n",
    "\n",
    "##### Description:\n",
    "\n",
    "After gathering which columns contain NA/NULL values into Series and will be using the missingno & matplotlib library combo. library to generate a chart that visualizes the gaps within the data. The whitespace within the histogram chart represents missing values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing_data_columns = missing_data['Column']\n",
    "\n",
    "msno.matrix(medical_data[missing_data_columns], fontsize = 12, labels = True)\n",
    "plt.title('Columns with Missing Data')\n",
    "plt.show()\n",
    "\n",
    "#Need to filter out categorical columnas as those are a MODE Imputation. Need to check numerical columns for Normal or Left/Right Skew.\n",
    "category_columns = pd.Series(list(convert_to_category.keys()))\n",
    "numerical_nas = missing_data_columns[~missing_data_columns.isin(category_columns)]\n",
    "\n",
    "for numerical_column in numerical_nas:\n",
    "    df = medical_data[numerical_column]\n",
    "    df.hist()\n",
    "    plt.title(f\"Distribution of '{numerical_column}'\")\n",
    "    plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting Outliers\n",
    "\n",
    "##### Description:\n",
    "\n",
    "Here we will gather the columns that have a numerical data type of `int64` and `float64`. We'll loop through each column name and create and display a boxplot. Each boxplot will need to be visually checke to see if there are any data points out side of the boxplot whiskers, which indicates there are outliers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interquartile Range (IQR)\n",
    "# Outliers are values falling outside the 25th and 75th percentile\n",
    "# https://www.vedantu.com/maths/interquartile-range\n",
    "def getOutliers_IQR(dataframe: pd.DataFrame, columnName: str):\n",
    "    variableOfInterest = dataframe[columnName]\n",
    "\n",
    "    quantile1 = variableOfInterest.quantile(0.25)\n",
    "    quantile3 = variableOfInterest.quantile(0.75)\n",
    "\n",
    "    interquartile_range = quantile3 - quantile1\n",
    "\n",
    "    below_25_select = variableOfInterest < (quantile1 - 1.5 * interquartile_range)\n",
    "    above_75_select = variableOfInterest > (quantile3 + 1.5 * interquartile_range)\n",
    "\n",
    "    outliers = variableOfInterest[below_25_select | above_75_select]\n",
    "\n",
    "    summary = {\n",
    "        'Variable': [columnName],\n",
    "        'Total_Outliers': [outliers.count()],\n",
    "        'Outlier_Min_Value': [outliers.min()],\n",
    "        'Outlier_Max_Value': [outliers.max()]\n",
    "    }\n",
    "\n",
    "    summary_dataframe = pd.DataFrame(summary)\n",
    "\n",
    "    summary_dataframe.fillna(value=0, inplace=True)\n",
    "\n",
    "    return summary_dataframe\n",
    "\n",
    "# Get all numerical columns\n",
    "numerical_columns = medical_data.select_dtypes(include=[np.int64, np.float64]).columns\n",
    "\n",
    "numerical_quantitative = numerical_columns.get_indexer_for(['CaseOrder', 'Overweight', 'Anxiety'])\n",
    "numerical_columns = numerical_columns.delete(numerical_quantitative)\n",
    "\n",
    "print(f\"Boxplots to be generated '{numerical_columns.size}'\")\n",
    "\n",
    "for column in numerical_columns:\n",
    "    sb.boxplot(x = medical_data[column])\n",
    "    plt.title(f\"Boxplot of {column}\")\n",
    "    plt.show()\n",
    "    print(getOutliers_IQR(medical_data, column))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treatment for Duplicates\n",
    "\n",
    "##### Description:\n",
    "\n",
    "What defined a duplicate did not produce any entries. There are no treatments needed for duplicates for the `Medical Data Set`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treatments for Missing Data\n",
    "\n",
    "##### Description:\n",
    "    The columns listed below with missing data we will chart their distribution to help choose with statistical central tendency value to use for imputation.\n",
    "\n",
    "**Columns with missing data**\n",
    "* Children - 2588 - Numerical\n",
    "* Age -2414 - Numerical\n",
    "* Income - 2464 - Numerical\n",
    "* Soft_drink - 2467 - Categorical\n",
    "* Overweight - 982 - Categorical (Numerical needing converting to Categorical Yes/No)\n",
    "* Anxiety - 984 - Categorical (Numerical needing converting to Categorical Yes/No)\n",
    "* Initial_days - 1056 - Numerical\n",
    "\n",
    "<br>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ‘kde’ : Kernel Density Estimation plot\n",
    "  \n",
    "imputations = {\n",
    "     'Children': int(medical_data['Children'].median()) #Right skewed\n",
    "    ,'Age': int(medical_data['Age'].mode()) #U-Shaped [Bi-Modal]\n",
    "    ,'Income': medical_data['Income'].median() #Right skewed\n",
    "    ,'Soft_drink': medical_data['Soft_drink'].mode()[0] #Categorical\n",
    "    ,'Overweight': int(medical_data['Overweight'].mode()[0]) #Categorical\n",
    "    ,'Anxiety': int(medical_data['Anxiety'].mode()[0]) #Categorical\n",
    "    ,'Initial_days': medical_data['Initial_days'].mode()[0] #U-Shaped Bi-Modal\n",
    "}\n",
    "\n",
    "imputated_medical_data = medical_data.fillna(imputations)\n",
    "\n",
    "#Visualization check\n",
    "msno.matrix(imputated_medical_data[missing_data_columns], fontsize=12, labels=True)\n",
    "plt.title('Missing Data columns after imputation.')\n",
    "plt.show()\n",
    "\n",
    "for numerical_column in numerical_nas:\n",
    "    numericals = medical_data[numerical_column]\n",
    "    numericals.hist()\n",
    "    plt.title(f\"Distribution of '{numerical_column}' after imputation.\")\n",
    "    plt.show()\n",
    "\n",
    "convert_to_int64 = {\n",
    "    'Age': np.int64,\n",
    "    'Children': np.int64\n",
    "}\n",
    "\n",
    "imputated_medical_data = imputated_medical_data.astype(convert_to_int64)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treatment for Outliers\n",
    "\n",
    "##### Description:\n",
    "\n",
    "The treatment plan for the outliers is in the `Medical Dataset` is Retain with noting of their existence. The values that have presented themselves as outliers are valid values within the context of the given variables. There is one variable (column) `VitD_levels` that have a weird mix of outliers at first glance but are valid. To help with the understanding of the `VitD_levels` a new variable(column) will be calculated. It will be the human readable version of the variables that falls into 3 levels/bins. Low, Adequate, and High are categorical values that correspond to Vitmin D Level ranges.\n",
    "\n",
    "**Vitamin D Level Ranges:**\n",
    "* Low -> 12 or below\n",
    "* Adequate -> 20 or above\n",
    "* High -> 50 or above "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.medicalnewstoday.com/articles/normal-vitamin-d-levels#function\n",
    "vitamin_d_bins = [0, 20, 50, np.inf]\n",
    "vitamin_d_categories = ['Low', 'Adequate', 'High']\n",
    "\n",
    "vitd_levels_group = pd.cut(imputated_medical_data['VitD_levels'], bins=vitamin_d_bins, labels=vitamin_d_categories)\n",
    "\n",
    "vitd_level_index = imputated_medical_data.columns.get_loc('VitD_levels')\n",
    "imputated_medical_data.insert((vitd_level_index + 1), 'VitD_levels_level', vitd_levels_group)\n",
    "\n",
    "chart_data = imputated_medical_data['VitD_levels_level'].value_counts()\n",
    "chart_data.plot.bar(x='Vitamin D Range', y='Customer Count')\n",
    "plt.title('Number of customers in each Vitamin D range.')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detecting 0/1's that need Re-Expression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "noyes_as_bits = [0, 1]\n",
    "columns_to_reexpress = []\n",
    "\n",
    "numerical_columns = medical_data.select_dtypes(include=[np.int64, np.float64]).columns\n",
    "\n",
    "for column in numerical_columns:\n",
    "    if imputated_medical_data[column].isin(noyes_as_bits).all():\n",
    "        columns_to_reexpress.append(column)\n",
    "\n",
    "print(f\"Re-Expression needed for {columns_to_reexpress}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Treatment for Re-Expression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detected values of pure 0/1's should be Re-Expressed into Yes/No.\n",
    "for column in columns_to_reexpress:\n",
    "    imputated_medical_data[column] = imputated_medical_data[column].map({1: 'Yes', 0: 'No'})\n",
    "\n",
    "imputated_medical_data[columns_to_reexpress].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Exporting the finalized cleaned-up data to csv file\n",
    "\n",
    "##### Description:\n",
    "\n",
    "* [to_csv documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_csv.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputated_medical_data.to_csv(r'./medical_cleaned_data.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Principle Component Analysis (PCA)\n",
    "\n",
    "* Must be run on cleaned data\n",
    "* Must only include numerical data of the same scale\n",
    "* Group each component based on similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "medical_data_clean = imputated_medical_data\n",
    "\n",
    "#Use Discrete and Continious data only\n",
    "pca_columns = ['Lat', 'Lng', 'Population', 'Age', 'Children', 'Income', 'VitD_levels', 'Full_meals_eaten', 'VitD_supp', 'Initial_days', 'TotalCharge', 'Additional_charges']\n",
    "\n",
    "pca_df = medical_data_clean[pca_columns]\n",
    "\n",
    "#normalization (AH HA MOMENT: This makes sense as to why outliers can be damaging to analysis)\n",
    "#Wildly skewed outliers will pull the math in uncertain directions\n",
    "pca_normalized = (pca_df - pca_df.mean()) / pca_df.std()\n",
    "\n",
    "pca = PCA(n_components=pca_normalized.shape[1])\n",
    "print(pca) #Should be PCA(n_component=12)\n",
    "\n",
    "pca.fit(pca_normalized)\n",
    "\n",
    "\n",
    "component_columns = []\n",
    "for i in range(1, len(pca_columns) + 1):\n",
    "    component_columns.append(f\"PC{i}\")\n",
    "\n",
    "pca_result = pd.DataFrame(pca.transform(pca_normalized), columns=component_columns)\n",
    "#pca_result\n",
    "\n",
    "pca_loadings = pd.DataFrame(pca.components_.T, columns=component_columns, index=pca_normalized.columns)\n",
    "pca_loadings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Selecting PCs\n",
    "\n",
    "##### Kaiser Rule (Eigenvalues):\n",
    "Must calculate covariance and vectors; then define eigenvalues before performing scree plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "covariant_matrix = np.dot(pca_normalized.T, pca_normalized) / pca_df.shape[0]\n",
    "eigenvalues = [np.dot(eigenvector.T, np.dot(covariant_matrix, eigenvector)) for eigenvector in pca.components_]\n",
    "\n",
    "print(eigenvalues)\n",
    "\n",
    "plt.plot(eigenvalues)\n",
    "plt.xlabel('Component Number')\n",
    "plt.ylabel('Eigenvalues')\n",
    "plt.axhline(y=1, color='red')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "40d3a090f54c6569ab1632332b64b2c03c39dcf918b08424e98f38b5ae0af88f"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
