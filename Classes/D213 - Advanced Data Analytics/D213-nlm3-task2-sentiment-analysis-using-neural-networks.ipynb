{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# D213 - Advanced Data Analytics\n",
    "### NLM3 Task 2: Sentiment Analysis Using Neural Networks\n",
    "#### Advanced Data Analytics — D213\n",
    "#### PRFA — NLM3\n",
    "> André Davis\n",
    "> StudentID: 010630641\n",
    "> MSDA\n",
    ">\n",
    "> Competencies\n",
    "> 4030.7.1 : Constructing Neural Networks\n",
    "> The graduate builds neural networks in the context of machine-learning modeling.\n",
    "> \n",
    "> 4030.7.3 : Natural Language Processing\n",
    "> The graduate extracts insights from text data using effective and appropriate natural language processing (NLP) models."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9a0a6f3a9c4c7b83"
  },
  {
   "cell_type": "markdown",
   "source": [
    "##### Table of Contents\n",
    "\n",
    " <ul>\n",
    "    <li><a href=\"#documentation\">Documentation</a></li>\n",
    "    <li><a href=\"#research-question\">A1: Research Question</a></li>\n",
    "    <li><a href=\"#objectives\">A2: Objectives Or Goals</a></li>\n",
    "    <li><a href=\"#neural-networks-identification\">A3: Prescribed Network Neural Network Identification</a></li>\n",
    "    <li><a href=\"#data-exploration\">B1: Data Exploration</a></li>\n",
    "    <li><a href=\"#tokenization-process\">B2: Tokenization</a></li>\n",
    "    <li><a href=\"#padding-process\">B3: Padding Process</a></li> \n",
    "    <li><a href=\"#categories-of-sentiment\">B4: Categories Of Sentiment</a></li>\n",
    "    <li><a href=\"#data-preparation\">B5: Steps To Prepare the Data</a></li>\n",
    "    <li><a href=\"#copy-of-prepared-data\">B6: Prepared Dataset</a></li>\n",
    "    <li><a href=\"#tensorflow-model-summary\">C1: Model Summary</a></li>\n",
    "    <li><a href=\"#network-architecture\">C2: Network Architecture</a></li>\n",
    "    <li><a href=\"#hyperparameters\">C3: Hyperparameters</a></li>\n",
    "    <li><a href=\"#stopping-criteria\">D1: Stopping Criteria</a></li>\n",
    "    <li><a href=\"#fitness\">D2: Fitness</a></li>\n",
    "    <li><a href=\"#training-process\">D3: Training Process</a></li>\n",
    "    <li><a href=\"#predictive-accuracy\">D4: Predictive Accuracy</a></li>\n",
    "    <li><a href=\"#source-code\">E: Code</a></li> \n",
    "    <li><a href=\"#functionality\">H: Functionality</a></li> \n",
    "    <li><a href=\"#recommendations\">G: Recommendeds</a></li>\n",
    "    <li><a href=\"#reporting\">H: Reporting</a></li>\n",
    "    <li><a href=\"#code-references\">I: Sources for Thirday Party Code</a></li>\n",
    "    <li><a href=\"#source-references\">J: Source References</a></li>    \n",
    "  </ul>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a6f4b1b44192be39"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Documentation\n",
    "\n",
    " * [TensorFlow](https://www.tensorflow.org/)\n",
    " * [Keras](https://keras.io/)\n",
    "     * [Dot Products](https://www.khanacademy.org/math/multivariable-calculus/thinking-about-multivariable-function/x786f2022:vectors-and-matrices/a/dot-products-mvc)    "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "72638253c5494f7c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"research-question\"></a>\n",
    "# A1: Research Question\n",
    "\n",
    "Is it feasible to ascertain the sentiment polarity—whether positive or negative—of an IMDb movie review to a reasonably reliable extent, solely based on the textual content of the review?"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acf84ccb3d1ed8e3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"objectives\"></a>\n",
    "# A2: Objectives and Goals of Analysis\n",
    "\n",
    "The main goal of this analysis is to build a neural network model that can fairly accurately tell if an IMDb movie review is positive or negative based on its text. A secondary goal is to try out different neural network setups and settings to find which one works best for our data and aim."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46d89ab2f5ad3e9e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"neural-networks-identification\"></a>\n",
    "# A3: Prescribed Network Neural Network Identification\n",
    "\n",
    "> Identify an industry-relevant type of neural network that can be trained to produce useful text classification predictions on text sequences on the selected data set.\n",
    "\n",
    "There are quite a few text-classification neural networks that can be used. Because this is a `WGU Performance Assessment` and most personal laptops don't have the computing power to perform some of the more complex neural networks without advanced GPU support [`Feedforward Neural Networks (FNN)`](https://en.wikipedia.org/wiki/Feedforward_neural_network). This is an advanced topic, and this particular neural network is known for its simplicity to implement and ability to function without higher end hardware.\n",
    "\n",
    "It must be noted that because of its simplicity and low-resource needs, it does come with some limitations, which include:\n",
    "\n",
    "1. Loss of neighborhood information (Suman, 2020)\n",
    "2. More parameters to optimize (Suman, 2020)\n",
    "3. It's not Translation invariance (Suman, 2020)\n",
    "\n",
    "The limitations stemming from the lack of awareness regarding neighboring information preclude Feedforward Neural Networks (FNN) from effectively identifying patterns in data structures such as images, where understanding the relationship between neighboring pixels is crucial. However, in the context of text analysis for performance assessment, these limitations are not particularly detrimental."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8ab0672265087149"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-exploration\"></a>\n",
    "# B1: Exploratory Data Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c5cee6834de79fd8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "!pip install numpy\n",
    "!pip install pandas\n",
    "!pip install matplotlib\n",
    "!pip install scikit-learn\n",
    "!pip install tensorflow==2.14.0"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "165a4e30d3e7e4a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "import inspect, json\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "#Tensor Flow Configuration\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Embedding, Flatten\n",
    "from keras.models import Sequential\n",
    "\n",
    "\n",
    "print(f'TensorFlow Version: {tf.__version__}')\n",
    "print('\\n\\n')\n",
    "\n",
    "'''\n",
    "File format as presented in the readme.txt:\n",
    "\n",
    "=======\n",
    "Format:\n",
    "=======\n",
    "sentence \\t score \\n\n",
    "\n",
    "\n",
    "=======\n",
    "Details:\n",
    "=======\n",
    "Score is either 1 (for positive) or 0 (for negative)\n",
    "'''\n",
    "imdb_columns = ['review', 'sentiment_score']\n",
    "imdb_reviews = pd.read_csv('./imdb_labelled.txt', engine='python', sep='\\t+', header=None, names=imdb_columns)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dc6813b056a56039"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(imdb_reviews.info())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d7a3e19ed7a559b"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(imdb_reviews.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "da5dbdc84104798e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "print(imdb_reviews.describe())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6f80253b323d7040"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "readme.txt states that the data should contain 500 positive and 500 negative sentences, a 50/50 split.\n",
    "\n",
    "Verifying dataset is complete\n",
    "'''\n",
    "\n",
    "total_positive_sentiments = len(imdb_reviews[imdb_reviews['sentiment_score'] == 1])\n",
    "total_negative_sentiments = len(imdb_reviews[imdb_reviews['sentiment_score'] == 0])\n",
    "\n",
    "print(f'Positive Sentiments Loaded: {total_positive_sentiments}')\n",
    "print(f'Negative Sentiments Loaded: {total_negative_sentiments}')\n",
    "\n",
    "assert total_positive_sentiments == 500, 'Failed to load all the positive sentiment scores'\n",
    "assert total_negative_sentiments == 500, 'Failed to load all the negative sentiment scores'\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "77dc2996bb63271e"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Check for missing values\n",
    "'''\n",
    "missing_data_check = imdb_reviews.isna().sum()\n",
    "\n",
    "assert missing_data_check.review == 0, 'Reviews should not contain an missing data'\n",
    "assert missing_data_check.sentiment_score == 0, 'Sentiment Scores should not contain any missing data'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "46002096a7b58e8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Chart Distribution of Sentiment Score to visually check 50/50 dataset assumption.\n",
    "'''\n",
    "\n",
    "sentiment_counts = [total_negative_sentiments, total_positive_sentiments]\n",
    "\n",
    "_, (hist_axes, pie_axis) = plt.subplots(1, 2, figsize=(12, 5))\n",
    "\n",
    "hist_axes.hist(imdb_reviews['sentiment_score'], bins=[-.5, .5, 1.5], rwidth=.5, color='green', alpha=.7)\n",
    "hist_axes.set_xlabel('Sentiment Score')\n",
    "hist_axes.set_ylabel('Count')\n",
    "hist_axes.set_title('Sentiment Score Histogram Distribution')\n",
    "\n",
    "for index, sentiment_count in enumerate(sentiment_counts):\n",
    "    hist_axes.text(index, (sentiment_count / 2), 'Negative' if index == 0 else 'Positive', color='black', ha='center', va='center')\n",
    "\n",
    "pie_axis.pie(sentiment_counts, labels=['Negative', 'Positive'], autopct='%1.1f%%', startangle=90)\n",
    "pie_axis.set_title('Sentiment Scores Pie Distribution')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9c4daaa9cfd344cd"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''\n",
    "Custom Utility functions for later activities\n",
    "'''\n",
    "\n",
    "def nameof(obj:any, g:dict=globals()) -> str:\n",
    "    \"\"\"\n",
    "    :param obj: Any object that we want to return the string name of\n",
    "    :type obj: any\n",
    "     \n",
    "    :param g: dictionary of globally accessible objects\n",
    "    :type g: dict\n",
    "    \n",
    "    :return: a string representation of the objects name\n",
    "    \"\"\"\n",
    "    return [name for name in g if g[name] is obj][0]\n",
    "\n",
    "#test nameof function\n",
    "assert nameof(mean_squared_error) ==  'mean_squared_error', 'nameof function should be returning the name of the object'"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cc5f23e007877f00"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"tokenization-process\"></a>\n",
    "# B2: Tokenization\n",
    "\n",
    "\"Tokenization is the process of breaking down a piece of text into small units called tokens. A token may be a word, part of a word or just characters like punctuation.\" (Perry, n.d.). For a simple example, we could end up with a text containing *\"Rick and Morty go on adventures.\"* Then during the tokenization process ('chunking') we would potentially end up with a collection of tokens such as:\n",
    "\n",
    "1. Rick\n",
    "2. and\n",
    "3. Morty\n",
    "4. go\n",
    "5. on\n",
    "6. adventures\n",
    "7. .\n",
    "\n",
    "Take notice that the period (.) became a token as well. In the vectorization process, sometimes a text is standardized where punctuation and casing are removed.\n",
    "\n",
    "There are many different libraries and ways to perform tokenization such as [`Natural Language Toolkit -NLTK`](https://www.nltk.org/). For the purposes of this performance assessment the [`Keras`](https://keras.io/) [`TextVectorization`](https://keras.io/api/layers/preprocessing_layers/core_preprocessing_layers/text_vectorization/) will be used."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "19732814baf2d8a8"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "'''Split the Reviews into 80%/20% training and test data.'''\n",
    "train_reviews, test_reviews = train_test_split(imdb_reviews, test_size=.2, random_state=999)\n",
    "\n",
    "total_features = 5000\n",
    "out_of_vocabulary_token = '{OOV}' \n",
    "\n",
    "'''\n",
    "To help models fail more gracefully and not ignoring sentences by using a replacement token during transformation.\n",
    "Words that fall out of vocabulary are words that were not in the original training set.\n",
    "\n",
    "Trained with \"I like programming\"\n",
    "Tested with \"I like coding\" which is converted to \"I like {OOV}\"\n",
    "'''\n",
    "\n",
    "training_reviews = train_reviews[imdb_columns[0]]\n",
    "tokenizer = Tokenizer(num_words=total_features, oov_token=out_of_vocabulary_token)\n",
    "tokenizer.fit_on_texts(training_reviews)\n",
    "\n",
    "word_counts = tokenizer.word_counts\n",
    "word_counts_data = json.loads(json.dumps(word_counts, indent=4))\n",
    "\n",
    "token_df_data = {\n",
    "    'Token': list(word_counts_data.keys()),\n",
    "    'Count': list(word_counts_data.values())\n",
    "}\n",
    "\n",
    "trained_tokens_df = pd.DataFrame(token_df_data)\n",
    "trained_tokens_df = trained_tokens_df.sort_values(by='Count', ascending=False)\n",
    "print(trained_tokens_df.head(20))\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4e7f4134e00f0ddb"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"padding-process\"></a>\n",
    "# B3: Padding Process\n",
    "\n",
    "In the machine learning realm, there are many models that require consistent length inputs. Padding is pre-processing step where adding extra values (usually zeros) to data to make them all the same size. This is done because many machine learning models require consistent input sizes. For example, in processing text, if we have sentences of different lengths but our model expects all sentences to have the same number of words, we add extra \"empty\" words to shorter sentences until they match the length of the longest one. This ensures the model can handle all the data uniformly."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f503c4111573ff1a"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "embeddings = tokenizer.texts_to_sequences(training_reviews)\n",
    "padded_embeddings = pad_sequences(embeddings, padding='post')\n",
    "\n",
    "describe_embeddings = f'''\n",
    "Sample of Sequences (Embeddings) and Padded Sequences (Padded Embeddings)\n",
    "-------------------------------------------------------------------------\n",
    "Embeddings: \n",
    "{embeddings[0]}\n",
    "\n",
    "Padded Embeddings: \n",
    "{padded_embeddings[0]}\n",
    "'''\n",
    "print(describe_embeddings)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5dfcf50f2c8c4a24"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"categories-of-sentiment\"></a>\n",
    "# B4: Categories Of Sentiment\n",
    "\n",
    "The **Categories of Sentiment** for the [`imdb_labelled dataset`](https://archive.ics.uci.edu/dataset/331/sentiment+labelled+sentences) is Binary Sentiment Classification as there are only two possible classifications. The classification categories are 1—Positive or 0—Negative. Demonstrated in the below code."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "54b1d366ba44fd4f"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "sentiment_scores = imdb_reviews[imdb_columns[1]]\n",
    "\n",
    "total_categories_of_sentiment = sentiment_scores.nunique()\n",
    "available_categories_of_sentiment = list(sentiment_scores.value_counts().index)\n",
    "\n",
    "assert total_categories_of_sentiment == 2, 'The total categories of sentiment should have been 2 as the IMDB reviews are either positive or negative'\n",
    "assert available_categories_of_sentiment == [0, 1], 'Category values should only include 0 or 1, representing Negative or Positive'\n",
    "\n",
    "sentiment_score_label = {\n",
    "    0: 'Negative',\n",
    "    1: 'Positive'\n",
    "}\n",
    " \n",
    "categories_of_sentiment_summary = f'''\n",
    "Total Categories of Sentiment: {total_categories_of_sentiment}\n",
    "Available Categories of Sentiment: {available_categories_of_sentiment}\n",
    "\n",
    "Legend: \n",
    " 0 - {sentiment_score_label.get(0)}\n",
    " 1 - {sentiment_score_label.get(1)}   \n",
    "'''\n",
    "\n",
    "print(categories_of_sentiment_summary)\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8572c250f91cb2d5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-preparation\"></a>\n",
    "# B5: Steps To Prepare the Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e029be5499a7d6ad"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"copy-of-prepared-data\"></a>\n",
    "# B6: Prepared Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c8ea2329d210e14c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"tensorflow-model-summary\"></a>\n",
    "# C1: Model Summary"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8156d83340e0130c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"network-architecture\"></a>\n",
    "# C2: Network Architecture"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9b90d42666bad852"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"hyperparameters\"></a>\n",
    "# C3: Hyperparameters\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b5076253c258201f"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"stopping-criteria\"></a>\n",
    "# D1: Stopping Criteria"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d52d548523b3589"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"fitness\"></a>\n",
    "# D2: Fitness"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "69e8dc0bde2f3d86"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"training-process\"></a>\n",
    "# D3: Training Process"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5c613d3410f5e5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"predictive-accuracy\"></a>\n",
    "# D4: Predictive Accuracy\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "8926612b310cbcc8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"source-code\"></a>\n",
    "# E: Code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "583e94b2083b1df1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"functionality\"></a>\n",
    "# H: Functionality"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "676538644d2f2443"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"recommendations\"></a>\n",
    "# G: Recommendations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9808f066bc992da0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"reporting\"></a>\n",
    "# H: Reporting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "764d2e6cad998a0d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"code-references\"></a>\n",
    "# I: Sources for Third Party Code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "200bbc8686c2c44e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"source-references\"></a>\n",
    "# J: Source References\n",
    "\n",
    " * Kotzias,Dimitrios. (2015). Sentiment Labelled Sentences. UCI Machine Learning Repository. https://doi.org/10.24432/C57604. <br /> <br />\n",
    " * Géron, A. (2022). Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems. <br /><br /> \n",
    " * Suman, A. (2020, Sept). Limitation of NN and CNN. Medium. https://anjanisuman.medium.com/limitation-of-nn-and-cnn-ee21a4cdc9eb <br /> <br />\n",
    " * Tal Perry. (n.d.). What is Tokenization in Natural Language Processing? Retrieved from https://www.machinelearningplus.com/nlp/what-is-tokenization-in-natural-language-processing/"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0576134a9f9b661"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "d4902bbd3a0b1e39"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
