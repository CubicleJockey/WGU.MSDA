{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# D213 - Advanced Data Analytics\n",
    "### NLM3 Task 1: Time Series Modeling\n",
    "#### Advanced Data Analytics — D213\n",
    "#### PRFA — NLM3\n",
    "> André Davis\n",
    "> StudentID: 010630641\n",
    "> MSDA\n",
    ">\n",
    "> Competencies\n",
    "> 4030.7.2 : Time Series Analysis\n",
    "> The graduate applies time series models in generating forecasts. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5159a574136b03af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Table of Contents\n",
    "<ul>\n",
    "    <li><a href=\"#research-question\">A1: Research Question</a></li>\n",
    "    <li><a href=\"#objectives\">A2: Objectives and Goals of Analysis</a></li>\n",
    "    <li><a href=\"#assumptions\">B: Assumptions of Time Series Model</a></li>\n",
    "    <li><a href=\"#visualizations\">C1: Time Series Visualization</a></li>\n",
    "    <li><a href=\"#time-step-description\">C2: Description of Time Step Formatting</a></li>\n",
    "    <li><a href=\"#stationary-of-series\">C3: Stationarity of Series</a></li>\n",
    "    <li><a href=\"#data-preparation\">C4: Data Preparation & Explanation</a></li>\n",
    "    <li><a href=\"#copy-of-prepared-data\">C5: Copy of Prepared Data Set</a></li>\n",
    "    <li><a href=\"#annotated-findings-and-visualizations\">D1: Annotated Findings & Visualizations</a></li>\n",
    "    <li><a href=\"#arima-model-of-time-series-data\">D2: ARIMA Model of Time Series Data</a></li>\n",
    "    <li><a href=\"#forcast\">D3: Forecast</a></li>\n",
    "    <li><a href=\"#analysis\">D4: Analysis Output & Calculations</a></li>\n",
    "    <li><a href=\"#arima-code\">D5: ARIMA Model Code</a></li>\n",
    "    <li><a href=\"#results-of-analysis\">E1: Results of Analysis</a></li> \n",
    "    <li><a href=\"#forcast-visualizations\">E2: Visualization of Forecast</a></li> \n",
    "    <li><a href=\"#recommendations\">E3: Recommended Action</a></li>\n",
    "    <li><a href=\"#reporting\">F: Reporting</a></li>\n",
    "    <li><a href=\"#code-references\">G: Code References</a></li>\n",
    "    <li><a href=\"#source-references\">H: Source References</a></li>    \n",
    "</ul>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbc7159866cfc1e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part I: Research Question"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5ba327c4c6bb9b6b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"research-question\"></a>\n",
    "## A1: Research Question\n",
    "\n",
    "The research question explored in this report is: \"Is it possible to accurately and effectively forecast the daily revenues of [`WGU`](https://www.wgu.edu/) Hospital System in a manner that aligns closely with the actual observed daily revenues?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2fa5576050d0dec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"objectives\"></a>\n",
    "## A2: Objectives and Goals of Analysis\n",
    "\n",
    "The objective of this analysis is to accurately predict daily revenues for the [`WGU`](https://www.wgu.edu) Hospital System utilizing the available [`dataset`](https://access.wgu.edu/ASP3/aap/content/fj30d8sm59fc83ed9xsi.zip). The analysis employs an 80-20 split of the dataset, using the initial 80% as a training set to forecast the remaining 20%, which serves as a test set. This approach allows for the use of observed values as a benchmark for comparison. An ARIMA time series model will be utilized to analyze the training set and project the values in the test set.\n",
    "\n",
    "> ARIMA is a \"model runs *d* rounds of differencing to make the time series more stationary, then it applies a regular ARMA Model. When making forecasts, it uses this ARMA model, then it adds back the terms that were subtracted by differencing.\"(Géron, 2022)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dda2d2d52f3dcdc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part II: Method Justification"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "170b4fbf55fe8045"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"assumptions\"></a>\n",
    "## B: Assumptions of Time Series Model\n",
    "\n",
    ">The submission accurately summarizes each of the assumptions of a time series model. The summary includes stationarity and autocorrelated data.\n",
    "\n",
    "Assumptions of the ARMA Family of Models, including ARIMA include:\n",
    "\n",
    " 1. Data must not include outliers and/or anomalies \n",
    " 2. The time series data should exhibit stationary, devoid of any trends or seasonal fluctuations.\n",
    " 3. Datapoints in the past must be indicative of future datapoints in behavior.\n",
    " 4. The data must reflect a single variable and be classified as uni-variate to be modelled.\n",
    " 5. The data must be auto-correlated for ARIMA model to perform forecasting via Autoregressive Component \n",
    "\n",
    "Some observational notes about the [`WGU Medical Time Series Dataset`](https://access.wgu.edu/ASP3/aap/content/fj30d8sm59fc83ed9xsi.zip) and the assumption point #3. Because this is a Performance Assessment for graduate school, the data presented for this activity is pretty limited. There are 730 rows and because this is a daily record, this equals 2 years of daily data. It may or may not be enough information to know if the past data indicates future behavior."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a4559b80ecd1f2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part III: Data Preparation"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "ed55c409a7ed027c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"visualizations\"></a>\n",
    "## C1: Time Series Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acda6fae05bf6f4c"
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 731 entries, 0 to 730\n",
      "Data columns (total 2 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Day      731 non-null    int64  \n",
      " 1   Revenue  731 non-null    float64\n",
      "dtypes: float64(1), int64(1)\n",
      "memory usage: 11.6 KB\n"
     ]
    }
   ],
   "source": [
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.dates as mdates\n",
    "from sklearn.model_selection import train_test_split\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from pmdarima import auto_arima\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "medical_daily_revenue = pd.read_csv('./medical_time_series.csv')\n",
    "medical_daily_revenue.info()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:26:12.344033300Z",
     "start_time": "2023-10-11T19:26:12.239499500Z"
    }
   },
   "id": "69e91439d038ed2c"
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "DatetimeIndex: 731 entries, 2021-01-01 to 2023-01-01\n",
      "Freq: D\n",
      "Data columns (total 1 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   Revenue  731 non-null    float64\n",
      "dtypes: float64(1)\n",
      "memory usage: 11.4 KB\n",
      "\n",
      "Total Records: [731]\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "For a Time-Series it will be easier to work with actual dates rather than a single number in the span of 2 years.\n",
    "\n",
    "Because this is an academic performance assessment I will use the start data of Jan 1st 2021. I'm basing this off\n",
    "the year WGU was founded within \"The National Society of Leadership and Success\" + 1 year so the 2 year period ends in 2023 (current year of this assignment)\n",
    "\n",
    "To index with dates pd.date_range (https://pandas.pydata.org/docs/reference/api/pandas.date_range.html) will be used.\n",
    "'''\n",
    "\n",
    "date_range_indexes = pd.date_range(start='2021', periods=len(medical_daily_revenue), freq='D')\n",
    "medical_daily_revenue.set_index(date_range_indexes, inplace=True)\n",
    "medical_daily_revenue.drop('Day', axis=1, inplace=True)\n",
    "\n",
    "medical_daily_revenue.info()\n",
    "\n",
    "print(f'\\nTotal Records: [{len(medical_daily_revenue)}]')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-11T19:26:12.403716700Z",
     "start_time": "2023-10-11T19:26:12.256341500Z"
    }
   },
   "id": "22dfc7069136f453"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualization of the Medical Daily Revenue Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1baffb0ea87aa43"
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [],
   "source": [
    "def chart_time_series(x: pd.Series, y: pd.Series, title: str) -> None:\n",
    "    \"\"\"\n",
    "    :param x: x-coordinates data to plot\n",
    "    :type x: pd.Series\n",
    "     \n",
    "    :param y: y-coordinates data to plot\n",
    "    :type y: pd.Series\n",
    "    \n",
    "    :param title: Title for the plot\n",
    "    :type title: str\n",
    "    \n",
    "    :return: None \n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Daily Revenue - USD(M)')\n",
    "    plt.title(f'{title} first 2 years of Daily Revenue(M)')\n",
    "        \n",
    "    plt.plot(x, y)\n",
    "    \n",
    "    #generate trend line\n",
    "    date_as_num = mdates.date2num(x)\n",
    "    polynomial_coefficients = np.polyfit(date_as_num, y, 1)\n",
    "    polynomial_function = np.poly1d(polynomial_coefficients) \n",
    "    \n",
    "    plt.plot(x, polynomial_function(date_as_num), c='r', linestyle='--', label='Trendline')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "\n",
    "x_dates = medical_daily_revenue.index\n",
    "y_revenue = medical_daily_revenue['Revenue']\n",
    "\n",
    "chart_time_series(x_dates, y_revenue, 'WGU Revenue')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9b14a69c0878c5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "To initiate the Time Series Analysis, the 'Days' attribute, which originally contained values ranging from 1 to 731, was transformed into corresponding date values. These dates encapsulate a two-year period of daily revenue data for WGU Hospital, denominated in U.S. dollars. The selection of the start date was made for scholarly considerations, as the hospital's actual founding date was not provided. \n",
    "\n",
    "The dates and revenue data were graphically represented, accompanied by a trend-line, to facilitate the visual identification of stationarity or non-stationarity in the dataset. While an upward trend is discernible, the presence of spikes—characterized by peaks and valleys—suggests potential seasonality. Addressing this is essential for conducting a rigorous time series analysis. The stationarity of the data will be further confirmed using the [`Augmented Dickey-Fuller test`](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f0537908e30f2ff0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"time-step-description\"></a>\n",
    "## C2: Description of Time Step Formatting\n",
    "\n",
    "The format of the time series data is pretty straight forward. We have two variables(columns) called `Day` and `Revenue`. The data represents revenue in the millions per day for two years since the opening of the *WGU Hospital*. The data does not contain any missing revenue values or days as it's a complete data set starting at Day 1 and continuing through Day 731, which is two years worth of data. The fact the total data is 731 and not 730 could indicate that the 2 years spanned through a [leap year](https://en.wikipedia.org/wiki/Leap_year) in February."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dc5389e7e687e7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"stationary-of-series\"></a>\n",
    "## C3: Stationary of Series\n",
    "\n",
    "To rigorously assess the stationarity of the dataset, we will employ a dual-method approach. Initially, a secondary visual inspection will be conducted by plotting the [`Rolling Average (Moving Average)`](https://www.indeed.com/career-advice/career-development/what-is-rolling-average) alongside the original time series. Subsequently, quantitative verification will be performed using the [`Augmented Dickey-Fuller (ADF) test`](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test), focusing on the p-value and ADF statistic. This combination of visual and statistical methods aims to provide a comprehensive evaluation of data stationarity.\n",
    "\n",
    "> \"Augmented Dickey Fuller test (ADF Test) is a common statistical test used to test whether a given Time series is stationary or not. It is one of the most commonly used statistical test when it comes to analyzing the stationary of a series.\" (Prabhakaran, 2022)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7871775eb7d7a13"
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [],
   "source": [
    "'''\n",
    "Visually Plot Rolling Average\n",
    "'''\n",
    "def generate_rolling_plot(data: pd.DataFrame, window_size: int = 24) -> None:\n",
    "    \"\"\"\n",
    "    :param data: data to performing rolling average on\n",
    "    :type data: pd.DataFrame\n",
    "    \n",
    "    :param window_size:  number of months for the rolling average window size\n",
    "    :type: window_size: int\n",
    "    \n",
    "    :return: None\n",
    "    \n",
    "    Documentation: \n",
    "        * Rolling - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.rolling.html\n",
    "        * Mean - https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.mean.html\n",
    "    \"\"\"\n",
    "    rolling = data.rolling(window=window_size)\n",
    "    rolling_means = rolling.mean()\n",
    "    rolling_means.plot(figsize=(16,5))\n",
    "    \n",
    "generate_rolling_plot(medical_daily_revenue)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3c0f3e7efb0696c1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "Visually checking the Rolling Average it's pretty clear that the data is not stationary. To confirm this in a statistical manner we will now do the  [`Augmented Dickey-Fuller test`](https://en.wikipedia.org/wiki/Augmented_Dickey%E2%80%93Fuller_test). "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "9ed03f3b16b5b18c"
  },
  {
   "cell_type": "markdown",
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "5d63f8d71e669902"
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [],
   "source": [
    "'''\n",
    "Augmented Dickey-Fuller Documentation: \n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html\n",
    "\n",
    "statsmodels.tsa.stattools.adfuller(\n",
    "    x, \n",
    "    maxlag=None, \n",
    "    regression='c', \n",
    "    autolag='AIC', \n",
    "    store=False, \n",
    "    regresults=False\n",
    ")\n",
    "'''\n",
    "\n",
    "def execute_adfuller(data: pd.Series, title: str) -> None:\n",
    "    \"\"\"   \n",
    "    :param data: data to perform the Augmented Dickey-Fuller Test on\n",
    "    :type data: pd.DataFrame\n",
    "    \n",
    "    :param title: title for the chart\n",
    "    :type title: str\n",
    "    \n",
    "    :return: None\n",
    "    \"\"\"\n",
    "    adf, p_value, used_lag, nobs, critical_values, icbest = adfuller(data)\n",
    "    \n",
    "    print(f'ADF Statistic: {adf}')\n",
    "    print(f'p-value: {p_value}')\n",
    "    print(f'Number of lags used: {used_lag}')\n",
    "    print(f'Number of observations: {nobs}')\n",
    "    print(f'Critical Values: {critical_values}')\n",
    "    print(f'Maximized Information Criterion: {icbest}')\n",
    "    \n",
    "    print('\\n')\n",
    "    print('p-value Stationary Results:')\n",
    "    print('=============================================================')\n",
    "    is_data_stationary = p_value <= .05\n",
    "    \n",
    "    print(f'p-value check: {round(p_value, 4)} < .05')\n",
    "    if is_data_stationary:\n",
    "        print(f'{title} Time Series data is likely stationary.')\n",
    "        print(f'Reject the null hypothesis (stationary) ')\n",
    "    else:\n",
    "        print(f'{title} Time Series data is likely non-stationary.')\n",
    "        print(f'Fail to reject the null hypothesis (accept Alternative Hypothesis)')\n",
    "    print('=============================================================')\n",
    "    \n",
    "    print('\\n')\n",
    "    print('adf (test statistic) Results:')\n",
    "    print('=============================================================')\n",
    "    \n",
    "    print(f\"adf check (1%): {round(adf, 4)} < {round(critical_values['1%'], 4)}\")\n",
    "    print(f\"adf check (5%): {round(adf, 4)} < {round(critical_values['5%'], 4)}\")\n",
    "    print(f\"adf check (10%): {round(adf, 4)} < {round(critical_values['10%'], 4)}\")\n",
    "    \n",
    "    if adf < critical_values['1%']:\n",
    "        print(f'{title} Time Series data is stationary at 1% significance level.')\n",
    "    elif adf < critical_values['5%']:    \n",
    "        print(f'{title} Time Series data is stationary at 5% significance level.')\n",
    "    elif adf < critical_values['10%']:\n",
    "        print(f'{title} Time Series data is stationary at 10% significance level.')\n",
    "    else:\n",
    "        print(f'{title} Time Series data is likely non-stationary.')\n",
    "\n",
    "execute_adfuller(medical_daily_revenue['Revenue'], 'WGU Revenue')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b324c8394a9b89b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-preparation\"></a>\n",
    "## C4: Data Preparation & Explanation\n",
    "\n",
    "Time Series Analysis will require a little bit of data prepping. After preparing the data will also be split into training and testing data, so we can validate how well the model for the Time Series is performing.\n",
    "\n",
    "Steps:\n",
    "\n",
    " 1. Transform `Revenue` data into a stationary time series format by getting 'First discrete difference' of object using the [`.diff()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html) function of [`Pandas`](https://pandas.pydata.org/).\n",
    "    *  Stabilizes the mean and moves data to stationary\n",
    " 2. Removing missing values after transformation \n",
    " 3. Split transformed data into training and test datasets with an 80%/20% split. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1d628693ca6d21"
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "'''\n",
    "Use diff() function to get the Discrete Differences and then perform .dropna() to remove missing values.\n",
    "\n",
    "Description:\n",
    "    In time series analysis, discrete difference helps in understanding the change in values over time. It's similar to calculating the delta (change) between consecutive or seasonal data points.\n",
    "'''\n",
    "\n",
    "discrete_differences = medical_daily_revenue.diff()\n",
    "\n",
    "#drop the first row that tends to be empty\n",
    "discrete_differences = discrete_differences.dropna()\n",
    "\n",
    "revenue_discrete_differences = discrete_differences['Revenue']\n",
    "\n",
    "execute_adfuller(revenue_discrete_differences, 'Transformed WGU Revenue')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cba618c4d84ea412"
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "outputs": [],
   "source": [
    "'''\n",
    "Visual Check that Revenue Data is now Stationary\n",
    "'''\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Revenue (Millions USD')\n",
    "plt.title('Stationary Visualization Check (Differenced Daily Revenue)')\n",
    "\n",
    "plt.plot(discrete_differences)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18a52c002bf8ccb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This chart does not show any signs of trending or seasonality. The visual check confirms the p-value and adf value check of stationary."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "456bac29955b5eca"
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "outputs": [],
   "source": [
    "'''\n",
    "Visually Plot Rolling Average of the Data Differences\n",
    "'''\n",
    "\n",
    "generate_rolling_plot(revenue_discrete_differences)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "822ad1735b358c4b"
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "outputs": [],
   "source": [
    "'''\n",
    "Train and Test data splitting 80/20.\n",
    "'''\n",
    "\n",
    "train_data, test_data = train_test_split(discrete_differences, test_size=.2, shuffle=False, random_state=999)\n",
    "\n",
    "print('Training Data Top-Five')\n",
    "print(train_data.head())\n",
    "print('\\n')\n",
    "print('Testing Data Top-Five')\n",
    "print(test_data.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7dbb83926e8f0ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"copy-of-prepared-data\"></a>\n",
    "## C5: Copy of Prepared Data Set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdeb2cb850f60672"
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "outputs": [],
   "source": [
    "'''Saving Training Data'''\n",
    "train_data.to_csv('./time-series-training-data.csv')\n",
    "\n",
    "'''Saving Test Data'''\n",
    "test_data.to_csv('./time-series-testing-data.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e23f43ddd1581165"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part IV: Model Identification & Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2e248a3c03a3f5f8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"annotated-findings-and-visualizations\"></a>\n",
    "## D1: Annotated Findings & Visualizations\n",
    "\n",
    "Annotating the findings and supplying visualizations with those findings is going to include two processes:\n",
    "\n",
    " * [`auto_arima`](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html)\n",
    "    * **Purpose:** Forecasting\n",
    "    * Automatically discover the optimal order for an ARIMA model\n",
    "    * Uses SARIMAX Modeling\n",
    " * [`seasonal_decompose`](https://www.statsmodels.org/stable/generated/statsmodels.tsa.seasonal.seasonal_decompose.html)\n",
    "    * **Purpose:** Exploration / Decomposition\n",
    "    * Seasonal decomposition using moving averages."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9db168035450a2e"
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "outputs": [],
   "source": [
    "'''\n",
    "Auto Generate the Optimal Order for an ARIMA Model\n",
    "\n",
    "NOTE: Setting trace=True will allow us to see the different model runs before being returned the best option.\n",
    "'''\n",
    "\n",
    "auto_arima_results = auto_arima(revenue_discrete_differences, trace=True)\n",
    "print(auto_arima_results.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "df81d7daf2528f4d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "The [`WGU Medical Time Series Dataset`](https://access.wgu.edu/ASP3/aap/content/fj30d8sm59fc83ed9xsi.zip) being processed through the [`auto_arima`](https://alkaline-ml.com/pmdarima/modules/generated/pmdarima.arima.auto_arima.html) process concluded these results:\n",
    "\n",
    "Optimal **[`ARIMA`](https://en.wikipedia.org/wiki/Autoregressive_integrated_moving_average) (AutoRegressive Integrated Moving Average) Model** parameters:\n",
    "\n",
    "| Component               | Parameter                    | Optimal Value | Meaning                                                       |\n",
    "|-------------------------|------------------------------|---------------|---------------------------------------------------------------|\n",
    "| **AR** (AutoRegressive) | **p** (Autoregressive Order) | *1*           | Use 'First Lagged Value'                                      |\n",
    "| **I** (Integrated)      | **d** (Differencing Order)   | *0*           | Data is stationary, directly models original time-series data |\n",
    "| **MA** (Moving Average) | **q** (Moving Average Order) | *0*           | Will not use past forecast errors to model time-series        |\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1d6ac38919b0f96a"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"arima-model-of-time-series-data\"></a>\n",
    "## D2: ARIMA Model of Time Series Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b19697a981f8668"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [
    "p, d, q = auto_arima_results.order\n",
    "\n",
    "#confirm the properties match the summary data above\n",
    "assert p == 1, 'p(Autoregressive Order) should be [1] per D1 section summary'\n",
    "assert d == 0, 'd(Differencing Order) should be [0] per D1 section summary'\n",
    "assert q == 0, 'q(Moving Average Order) should be [0] per D1 section summary'\n",
    "\n",
    "arima_order = (p, d, q)\n",
    "\n",
    "arima_model = ARIMA(train_data, order=arima_order, freq='D')\n",
    "\n",
    "fitted_model = arima_model.fit()\n",
    "\n",
    "print(fitted_model.summary())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c998098039a6d162"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"forcast\"></a>\n",
    "## D3: Forecast"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ba92e4aa3f150f7"
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   },
   "id": "9e8860125b175ac0"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"analysis\"></a>\n",
    "## D4: Analysis Output & Calculations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c5f707e38d7eae6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"arima-code\"></a>\n",
    "## D5: ARIMA Model Code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29db37bbd3e2b147"
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Part V: Data Summary and Implications"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "25fbfede05777911"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"results-of-analysis\"></a>\n",
    "## E1: Results of Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5e0470a1e37f475"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"forcast-visualizations\"></a>\n",
    "## E2: Visualization of Forecast"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92f3c1b15aa93c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"recommendations\"></a>\n",
    "## E3: Recommended Action"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1aa984d0af066a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"reporting\"></a>\n",
    "## F: Reporting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af43c95b41813cac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"code-references\"></a>\n",
    "## G: Code References"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b0e183a73d445e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"source-references\"></a>\n",
    "## H: Source References\n",
    "\n",
    " * Géron, A. (2022). Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems. <br /><br />\n",
    " * Prabhakaran, S. (2022). Augmented Dickey Fuller Test (ADF Test) – must read guide. Machine Learning Plus. https://www.machinelearningplus.com/time-series/augmented-dickey-fuller-test/ "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2447b84e94f276dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
