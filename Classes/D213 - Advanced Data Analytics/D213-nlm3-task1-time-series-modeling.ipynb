{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# D213 - Advanced Data Analytics\n",
    "### NLM3 Task 1: Time Series Modeling\n",
    "#### Advanced Data Analytics — D213\n",
    "#### PRFA — NLM3\n",
    "> André Davis\n",
    "> StudentID: 010630641\n",
    "> MSDA\n",
    ">\n",
    "> Competencies\n",
    "> 4030.7.2 : Time Series Analysis\n",
    "> The graduate applies time series models in generating forecasts. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "5159a574136b03af"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Table of Contents\n",
    "<ul>\n",
    "    <li><a href=\"#research-question\">A1: Research Question</a></li>\n",
    "    <li><a href=\"#objectives\">A2: Objectives and Goals of Analysis</a></li>\n",
    "    <li><a href=\"#assumptions\">B: Assumptions of Time Series Model</a></li>\n",
    "    <li><a href=\"#visualizations\">C1: Time Series Visualization</a></li>\n",
    "    <li><a href=\"#time-step-description\">C2: Description of Time Step Formatting</a></li>\n",
    "    <li><a href=\"#stationary-of-series\">C3: Stationarity of Series</a></li>\n",
    "    <li><a href=\"#data-preparation\">C4: Data Preparation & Explanation</a></li>\n",
    "    <li><a href=\"#copy-of-prepared-data\">C5: Copy of Prepared Data Set</a></li>\n",
    "    <li><a href=\"#annotated-findings-and-visualizations\">D1: Annotated Findings & Visualizations</a></li>\n",
    "    <li><a href=\"#arima-model-of-time-series-data\">D2: ARIMA Model of Time Series Data</a></li>\n",
    "    <li><a href=\"#forcast\">D3: Forecast</a></li>\n",
    "    <li><a href=\"#analysis\">D4: Analysis Output & Calculations</a></li>\n",
    "    <li><a href=\"#arima-code\">D5: ARIMA Model Code</a></li>\n",
    "    <li><a href=\"#results-of-analysis\">E1: Results of Analysis</a></li> \n",
    "    <li><a href=\"#forcast-visualizations\">E2: Visualization of Forecast</a></li> \n",
    "    <li><a href=\"#recommendations\">E3: Recommended Action</a></li>\n",
    "    <li><a href=\"#reporting\">F: Reporting</a></li>\n",
    "    <li><a href=\"#code-references\">G: Code References</a></li>\n",
    "    <li><a href=\"#source-references\">H: Source References</a></li>    \n",
    "</ul>"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cbc7159866cfc1e8"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"research-question\"></a>\n",
    "# A1: Research Question\n",
    "\n",
    "The research question explored in this report is: \"Is it possible to accurately and effectively forecast the daily revenues of [`WGU`](https://www.wgu.edu/) Hospital System in a manner that aligns closely with the actual observed daily revenues?\""
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "a2fa5576050d0dec"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"objectives\"></a>\n",
    "# A2: Objectives and Goals of Analysis\n",
    "\n",
    "The objective of this analysis is to accurately predict daily revenues for the [`WGU`](https://www.wgu.edu) Hospital System utilizing the available [`dataset`](https://access.wgu.edu/ASP3/aap/content/fj30d8sm59fc83ed9xsi.zip). The analysis employs an 80-20 split of the dataset, using the initial 80% as a training set to forecast the remaining 20%, which serves as a test set. This approach allows for the use of observed values as a benchmark for comparison. An ARIMA time series model will be utilized to analyze the training set and project the values in the test set.\n",
    "\n",
    "> ARIMA is a \"model runs *d* rounds of differencing to make the time series more stationary, then it applies a regular ARMA Model. When making forecasts, it uses this ARMA model, then it adds back the terms that were subtracted by differencing.\"(Géron, 2022)."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dda2d2d52f3dcdc3"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"assumptions\"></a>\n",
    "# B: Assumptions of Time Series Model\n",
    "\n",
    ">The submission accurately summarizes each of the assumptions of a time series model. The summary includes stationarity and autocorrelated data.\n",
    "\n",
    "Assumptions of the ARMA Family of Models, including ARIMA include:\n",
    "\n",
    " 1. Data must not include outliers and/or anomalies \n",
    " 2. The time series data should exhibit stationary, devoid of any trends or seasonal fluctuations.\n",
    " 3. Datapoints in the past must be indicative of future datapoints in behavior.\n",
    " 4. The data must reflect a single variable and be classified as uni-variate to be modelled.\n",
    " 5. The data must be auto-correlated for ARIMA model to perform forecasting via Autoregressive Component \n",
    "\n",
    "Some observational notes about the [`WGU Medical Time Series Dataset`](https://access.wgu.edu/ASP3/aap/content/fj30d8sm59fc83ed9xsi.zip) and the assumption point #3. Because this is a Performance Assessment for graduate school, the data presented for this activity is pretty limited. There are 730 rows and because this is a daily record, this equals 2 years of daily data. It may or may not be enough information to know if the past data indicates future behavior."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2a4559b80ecd1f2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"visualizations\"></a>\n",
    "# C1: Time Series Visualization"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "acda6fae05bf6f4c"
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from statsmodels.tsa.stattools import adfuller\n",
    "from statsmodels.tsa.seasonal import seasonal_decompose\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from statsmodels.tsa.arima.model import ARIMA\n",
    "\n",
    "medical_daily_revenue = pd.read_csv('./medical_time_series.csv')\n",
    "medical_daily_revenue.info()\n",
    "\n",
    "print(f'\\nTotal Records: [{len(medical_daily_revenue)}]')"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-09-20T03:30:29.183858800Z",
     "start_time": "2023-09-20T03:30:29.093788400Z"
    }
   },
   "id": "69e91439d038ed2c"
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Visualization of the Medical Daily Revenue Dataset"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "1baffb0ea87aa43"
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "outputs": [],
   "source": [
    "def chart_time_series(data: pd.DataFrame, title: str) -> None:\n",
    "    plt.figure(figsize=(16,5))\n",
    "    plt.xlabel('Day')\n",
    "    plt.ylabel('Daily Revenue - USD(M)')\n",
    "    plt.title(f'{title} first 2 years of Daily Revenue(M)')\n",
    "    \n",
    "    x_days = data['Day']\n",
    "    y_revenue = data['Revenue']\n",
    "    plt.plot(x_days, y_revenue)\n",
    "    \n",
    "    #generate trend line\n",
    "    polynomial_coefficients = np.polyfit(x_days, y_revenue, 1)\n",
    "    polynomial_function = np.poly1d(polynomial_coefficients) \n",
    "    \n",
    "    plt.plot(x_days, polynomial_function(x_days), c='r', linestyle='--', label='Trendline')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "chart_time_series(medical_daily_revenue, 'WGU Revenue')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "f9b14a69c0878c5b"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"time-step-description\"></a>\n",
    "# C2: Description of Time Step Formatting\n",
    "\n",
    "The format of the time series data is pretty straight forward. We have two variables(columns) called `Day` and `Revenue`. The data represents revenue in the millions per day for two years since the opening of the *WGU Hospital*. The data does not contain any missing revenue values or days as it's a complete data set starting at Day 1 and continuing through Day 731, which is two years worth of data. The fact the total data is 731 and not 730 could indicate that the 2 years spanned through a [leap year](https://en.wikipedia.org/wiki/Leap_year) in February."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3dc5389e7e687e7d"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"stationary-of-series\"></a>\n",
    "# C3: Stationary of Series\n",
    "\n",
    "To test whether or not the data is stationary or not we will back-up the visual check with the Augmented Dickery-Fuller (ADF) test.\n",
    "\n",
    "> \"Augmented Dickey Fuller test (ADF Test) is a common statistical test used to test whether a given Time series is stationary or not. It is one of the most commonly used statistical test when it comes to analyzing the stationary of a series.\" (Prabhakaran, 2022)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7871775eb7d7a13"
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "outputs": [],
   "source": [
    "'''\n",
    "Augmented Dickey-Fuller Documentation: \n",
    "https://www.statsmodels.org/dev/generated/statsmodels.tsa.stattools.adfuller.html\n",
    "\n",
    "statsmodels.tsa.stattools.adfuller(\n",
    "    x, \n",
    "    maxlag=None, \n",
    "    regression='c', \n",
    "    autolag='AIC', \n",
    "    store=False, \n",
    "    regresults=False\n",
    ")\n",
    "'''\n",
    "\n",
    "def execute_adfuller(data: pd.Series, title: str) -> None:\n",
    "    adf, p_value, used_lag, nobs, critical_values, icbest = adfuller(data)\n",
    "    \n",
    "    print(f'ADF Statistic: {adf}')\n",
    "    print(f'p-value: {p_value}')\n",
    "    print(f'Number of lags used: {used_lag}')\n",
    "    print(f'Number of observations: {nobs}')\n",
    "    print(f'Critical Values: {critical_values}')\n",
    "    print(f'Maximized Information Criterion: {icbest}')\n",
    "    \n",
    "    print('\\n')\n",
    "    print('p-value Stationary Results:')\n",
    "    print('=============================================================')\n",
    "    is_data_stationary = p_value < .05\n",
    "    \n",
    "    print(f'p-value check: {round(p_value, 4)} < .05')\n",
    "    if is_data_stationary:\n",
    "        print(f'{title} Time Series data is likely stationary.')\n",
    "    else:\n",
    "        print(f'{title} Time Series data is likely non-stationary.')\n",
    "    print('=============================================================')\n",
    "    \n",
    "    print('\\n')\n",
    "    print('adf (test statistic) Results:')\n",
    "    print('=============================================================')\n",
    "    \n",
    "    print(f\"adf check (1%): {round(adf, 4)} < {round(critical_values['1%'], 4)}\")\n",
    "    print(f\"adf check (5%): {round(adf, 4)} < {round(critical_values['5%'], 4)}\")\n",
    "    print(f\"adf check (10%): {round(adf, 4)} < {round(critical_values['10%'], 4)}\")\n",
    "    \n",
    "    if adf < critical_values['1%']:\n",
    "        print(f'{title} Time Series data is stationary at 1% significance level.')\n",
    "    elif adf < critical_values['5%']:    \n",
    "        print(f'{title} Time Series data is stationary at 5% significance level.')\n",
    "    elif adf < critical_values['10%']:\n",
    "        print(f'{title} Time Series data is stationary at 10% significance level.')\n",
    "    else:\n",
    "        print(f'{title} Time Series data is likely non-stationary.')\n",
    "\n",
    "execute_adfuller(medical_daily_revenue['Revenue'], 'WGU Revenue')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "b324c8394a9b89b4"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"data-preparation\"></a>\n",
    "# C4: Data Preparation & Explanation\n",
    "\n",
    "Time Series Analysis will require a little bit of data prepping. After preparing the data will also be split into training and testing data, so we can validate how well the model for the Time Series is performing.\n",
    "\n",
    "Steps:\n",
    "\n",
    " 1. Transform `Revenue` data into a stationary time series format by getting 'First discrete difference of object' using the [`.diff()`](https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.diff.html) function of [`Pandas`](https://pandas.pydata.org/).\n",
    " 2. Removing missing values after transformation \n",
    " 3. Split transformed data into training and test datasets with an 80%/20% split. "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d1d628693ca6d21"
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "outputs": [],
   "source": [
    "'''\n",
    "Use diff() function to get the Discrete Differences and then perform .dropna() to remove missing values.\n",
    "'''\n",
    "\n",
    "discrete_differences = medical_daily_revenue.diff()\n",
    "discrete_differences = discrete_differences.dropna()\n",
    "\n",
    "#put correct days back instead of diff for day count\n",
    "#discrete_differences['Day'] = medical_daily_revenue['Day']\n",
    "\n",
    "diff_revenue = discrete_differences['Revenue']\n",
    "\n",
    "execute_adfuller(diff_revenue, 'Transformed WGU Revenue')"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "cba618c4d84ea412"
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "outputs": [],
   "source": [
    "'''\n",
    "Visual Check that Revenue Data is now Stationary\n",
    "'''\n",
    "\n",
    "plt.figure(figsize=(16,5))\n",
    "plt.xlabel('Day')\n",
    "plt.ylabel('Revenue')\n",
    "plt.title('Stationary Visualization Check')\n",
    "\n",
    "plt.plot(discrete_differences)"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "18a52c002bf8ccb9"
  },
  {
   "cell_type": "markdown",
   "source": [
    "This chart does not show any signs of trending or seasonality. The visual check confirms the p-value and adf value check of stationary."
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "456bac29955b5eca"
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "outputs": [],
   "source": [
    "'''\n",
    "Train and Test data splitting 80/20.\n",
    "'''\n",
    "\n",
    "train, test = train_test_split(discrete_differences, test_size=.2, shuffle=False, random_state=999)\n",
    "\n",
    "print(train.head())\n",
    "print(test.head())"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "c7dbb83926e8f0ed"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"copy-of-prepared-data\"></a>\n",
    "# C5: Copy of Prepared Data Set"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "fdeb2cb850f60672"
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "outputs": [],
   "source": [
    "'''Saving Training Data'''\n",
    "train.to_csv('./time-series-training-data.csv')\n",
    "\n",
    "'''Saving Test Data'''\n",
    "test.to_csv('./time-series-testing-data.csv')\n"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e23f43ddd1581165"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"annotated-findings-and-visualizations\"></a>\n",
    "# D1: Annotated Findings & Visualizations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e9db168035450a2e"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"arima-model-of-time-series-data\"></a>\n",
    "# D2: ARIMA Model of Time Series Data"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2b19697a981f8668"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"forcast\"></a>\n",
    "# D3: Forecast"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "3ba92e4aa3f150f7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"analysis\"></a>\n",
    "# D4: Analysis Output & Calculations"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2c5f707e38d7eae6"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"arima-code\"></a>\n",
    "# D5: ARIMA Model Code"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "29db37bbd3e2b147"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"results-of-analysis\"></a>\n",
    "# E1: Results of Analysis"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "d5e0470a1e37f475"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"forcast-visualizations\"></a>\n",
    "# E2: Visualization of Forecast"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "92f3c1b15aa93c7"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"recommendations\"></a>\n",
    "# E3: Recommended Action"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "e1aa984d0af066a1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"reporting\"></a>\n",
    "# F: Reporting"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "af43c95b41813cac"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"code-references\"></a>\n",
    "# G: Code References"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "4b0e183a73d445e1"
  },
  {
   "cell_type": "markdown",
   "source": [
    "<a id=\"source-references\"></a>\n",
    "# H: Source References\n",
    "\n",
    " * Géron, A. (2022). Hands-On Machine Learning with Scikit-Learn, Keras, and Tensorflow: Concepts, Tools, and Techniques to Build Intelligent Systems. <br /><br />\n",
    " * Prabhakaran, S. (2022). Augmented Dickey Fuller Test (ADF Test) – must read guide. Machine Learning Plus. https://www.machinelearningplus.com/time-series/augmented-dickey-fuller-test/ "
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "2447b84e94f276dc"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
